{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef885fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T09:18:05.695513Z",
     "start_time": "2021-12-17T09:18:03.125501Z"
    }
   },
   "source": [
    "# Using EchoClassesDataset()\n",
    "\n",
    "Miguel Xochicale [@mxochicale](https://github.com/mxochicale)  \n",
    "Jan2022\n",
    "\n",
    "\n",
    "## 1.1 Introduction\n",
    "This notebook presents prototypes to pre-process echocardiography datasets with the use of pytorch features. \n",
    "\n",
    "## 1.2 Running notebook\n",
    "\n",
    "1. Go to echocardiography repository path: `$HOME/repositories/echocardiography/`\n",
    "2. Open echocardiography repo in pycharm and in the terminal type:\n",
    "    ```\n",
    "    git checkout master # or the branch\n",
    "    git pull # to bring a local branch up-to-date with its remote version\n",
    "    ```\n",
    "3. Launch Notebook server\n",
    "    Go to you repository path: `cd $HOME/repositories/echocardiography/scripts/dataloaders` and type in the pycharm terminal:\n",
    "    ```\n",
    "    conda activate rt-ai-echo-VE \n",
    "    jupyter notebook\n",
    "    ```\n",
    "    which will open your web-browser.\n",
    "    \n",
    "    \n",
    "## 1.3 References\n",
    "* Gomez A. et al. 2021 https://github.com/vital-ultrasound/lung/blob/main/multiclass_pytorch/datasets/LUSVideoDataset.py \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f2aa0",
   "metadata": {},
   "source": [
    "## 2. Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d3efa",
   "metadata": {},
   "source": [
    "### 2.1 Setting imports and datasets paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f345efe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T08:58:31.480755Z",
     "start_time": "2022-01-27T08:58:31.476215Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from source.dataloaders.EchocardiographicVideoDataset import EchoClassesDataset\n",
    "\n",
    "HOME_PATH = os.path.expanduser(f'~')\n",
    "CONFIG_FILES_PATH= 'repositories/echocardiography/scripts/config_files'\n",
    "YML_FILE = os.path.join(HOME_PATH, CONFIG_FILES_PATH, 'config_echo_classes.yml')\n",
    "\n",
    "with open(YML_FILE, 'r') as yml:\n",
    "    config = yaml.load(yml, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b3729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T09:18:08.264310Z",
     "start_time": "2021-12-17T09:18:08.250178Z"
    }
   },
   "source": [
    "### 2.2 Setting variables and loading datasets using pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5109aecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T08:58:46.865571Z",
     "start_time": "2022-01-27T08:58:31.481640Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = EchoClassesDataset(\n",
    "    main_data_path=config['main_data_path'],\n",
    "    participant_videos_list=config['participant_videos_list'],\n",
    "    participant_path_json_list=config['participant_path_json_list'],\n",
    "    crop_bounds_for_us_image=config['crop_bounds_for_us_image'],\n",
    "    clip_duration=config['n_frames'],\n",
    "    device=device,\n",
    "    max_background_duration = 10\n",
    "    )\n",
    "\n",
    "clip_index = 10  # this must be within the dataset length\n",
    "data = dataset[clip_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ea2a6",
   "metadata": {},
   "source": [
    "### 2.3 Using dataloader with pre-processing image techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73552935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T08:58:00.971062Z",
     "start_time": "2022-01-27T08:57:46.223943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data retrieved\n",
      "tensor([[[[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]],\n",
      "\n",
      "         [[5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          ...,\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5],\n",
      "          [5, 5, 5,  ..., 5, 5, 5]]]], device='cuda:0', dtype=torch.uint8)\n",
      "1\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('data retrieved')\n",
    "\n",
    "\n",
    "clip, label, frame_number = data\n",
    "\n",
    "# print(type(data))\n",
    "print(clip)\n",
    "print(label)\n",
    "print(frame_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316f551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd312af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f167b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
