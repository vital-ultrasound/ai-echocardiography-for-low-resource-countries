{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef885fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T09:18:05.695513Z",
     "start_time": "2021-12-17T09:18:03.125501Z"
    }
   },
   "source": [
    "# Evaluation of models\n",
    "\n",
    "**Author**: Miguel Xochicale [@mxochicale](https://github.com/mxochicale)     \n",
    "**Contributors**: Nhat Phung Tran Huy [@huynhatd13](https://github.com/huynhatd13); Hamideh Kerdegari [@hamidehkerdegari](https://github.com/hamidehkerdegari);  Alberto Gomez [@gomezalberto](https://github.com/)  \n",
    "\n",
    "* Feb2022; March2022 \n",
    "* Aug2022; tidies notebook\n",
    "\n",
    "\n",
    "## Summary\n",
    "This notebook presents a learning pipeline to classify 4 chamber view from echocardiography datasets.\n",
    "\n",
    "### How to run the notebook\n",
    "\n",
    "1. Go to echocardiography repository path: `$HOME/repositories/echocardiography/`\n",
    "2. Open echocardiography repo in pycharm and in the terminal type:\n",
    "    ```\n",
    "    git checkout master # or the branch\n",
    "    git pull # to bring a local branch up-to-date with its remote version\n",
    "    ```\n",
    "3. Launch Notebook server  \n",
    "    Go to you repository path: `cd $HOME/repositories/echocardiography/scripts/dataloaders` and type in the pycharm terminal:\n",
    "    ```\n",
    "    conda activate rt-ai-echo-VE \n",
    "    jupyter notebook\n",
    "    ```\n",
    "    which will open your web-browser.\n",
    "    \n",
    "    \n",
    "### References\n",
    "* \"Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) - Discussion Paper and Request for Feedback\". https://www.fda.gov/media/122535/download \n",
    "* Gomez A. et al. 2021 https://github.com/vital-ultrasound/lung/blob/main/multiclass_pytorch/datasets/LUSVideoDataset.py \n",
    "* Kerdegari H. et al. 2021 https://github.com/vital-ultrasound/lung/tree/main/multiclass_tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f2aa0",
   "metadata": {},
   "source": [
    "# Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d3efa",
   "metadata": {},
   "source": [
    "## 1. Setting imports and datasets paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f345efe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:05.974566Z",
     "start_time": "2022-08-31T12:16:05.195324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.9.0\n",
      "Torchvision Version: 0.10.0a0\n",
      "FULL_PATH_FOR_YML_FILE: /home/mx19/repositories/echocardiography/scripts/config_files/users_paths_files/config_users_paths_files_username_mx19.yml\n",
      "FULL_REPO_MODEL_PATH: /home/mx19/repositories/echocardiography/data/models\n",
      "TRAINING_CURVES_PATH: /home/mx19/repositories/echocardiography/scripts/learning-pipeline/results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "#import matplotlib.animation as animation\n",
    "from IPython.display import HTML #to be used with HTML(animation.ArtistAnimation().to_jshtml())\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, \\\n",
    "                            ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as Data\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from source.dataloaders.EchocardiographicVideoDataset import EchoClassesDataset\n",
    "from source.helpers.various import concatenating_YAML_via_tags, \\\n",
    "                                    plot_dataset_classes, \\\n",
    "                                    split_train_validate_sets\n",
    "from source.helpers.learning_pipeline import get_class_distribution, \\\n",
    "                                            plot_from_dict, \\\n",
    "                                            creating_pair_of_clips, \\\n",
    "                                            pair_clips_labels, \\\n",
    "                                            animate_clips\n",
    "from source.helpers.learning_misc import train_loop, \\\n",
    "                                        test_loop\n",
    "\n",
    "from source.models.architectures import basicVGG, basicVGG3D, TrompNetV1, \\\n",
    "        LeNet5_source00, LeNet5_source01, LeNet5_source02, \\\n",
    "        AlexNet_source00, AlexNet_source01, AlexNet_source02, AlexNet_source03, \\\n",
    "        MobileNetV1, MobileNetV2, \\\n",
    "        SqueezeNet_source0, SqueezeNet_source1, SqueezeNet_source2, \\\n",
    "        EfficientNet_source0, \\\n",
    "        ShrapML_replication_v00, \\\n",
    "        basicVGG2D_04layers, basicVGG2D_07layers, basicVGG2D_13layers, basicVGG2D_NNlayers_sequence\n",
    "        #ShuffleNetV1, ShuffleNetV2 (require 3 channels of input images)\n",
    "\n",
    "HOME_PATH = os.path.expanduser(f'~')\n",
    "USERNAME = os.path.split(HOME_PATH)[1]\n",
    "\n",
    "REPOSITORY_PATH='repositories/echocardiography'\n",
    "FULL_REPO_PATH = HOME_PATH+'/'+REPOSITORY_PATH\n",
    "FULL_REPO_MODEL_PATH = HOME_PATH +'/' + REPOSITORY_PATH + '/data/models'\n",
    "CONFIG_FILES_PATH= REPOSITORY_PATH + '/scripts/config_files/users_paths_files'\n",
    "YML_FILE =  'config_users_paths_files_username_' + USERNAME + '.yml'\n",
    "FULL_PATH_FOR_YML_FILE = os.path.join(HOME_PATH, CONFIG_FILES_PATH, YML_FILE)\n",
    "PATH_for_temporal_files = os.path.join(HOME_PATH, 'datasets/vital-us/echocardiography/temporal-files')\n",
    "\n",
    "## Setting TRAINING_CURVES_PATH\n",
    "#CURRENT_PATH=os.path.abspath(os.getcwd())\n",
    "RESULTS_PATH='scripts/learning-pipeline/results'\n",
    "TRAINING_CURVES_PATH = os.path.join(FULL_REPO_PATH, RESULTS_PATH)\n",
    "\n",
    "## Setting FULL_PATH_FOR_YML_FILE\n",
    "yaml.add_constructor('!join', concatenating_YAML_via_tags)  ## register the tag handler\n",
    "with open(FULL_PATH_FOR_YML_FILE, 'r') as yml:\n",
    "    config = yaml.load(yml, Loader=yaml.FullLoader)\n",
    "\n",
    "## Printing Versions and paths\n",
    "print(f'PyTorch Version: {torch.__version__}')\n",
    "print(f'Torchvision Version: {torchvision.__version__}')    \n",
    "print(f'FULL_PATH_FOR_YML_FILE: {FULL_PATH_FOR_YML_FILE}' )\n",
    "print(f'FULL_REPO_MODEL_PATH: {FULL_REPO_MODEL_PATH}' )\n",
    "print(f'TRAINING_CURVES_PATH: {TRAINING_CURVES_PATH}' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b3729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T09:18:08.264310Z",
     "start_time": "2021-12-17T09:18:08.250178Z"
    }
   },
   "source": [
    "## 2. Setting variables and loading datasets using pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5109aecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:06.038259Z",
     "start_time": "2022-08-31T12:16:05.976108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time of the notebook 1661948165.980288\n",
      "Device: cuda\n",
      "train_set_size  0.7, test_set_size 0.15, val_test_size 0.15000000000000005\n",
      "---------------------------------------------\n",
      "  FILENAMES_len=16\n",
      "======= video_filenames: ('/01NVb-003-040/T2/01NVb-003-040-2 echo.mp4', '/01NVb-003-045/T2/01NVB-003-045-2 echo.mp4', '/01NVb-003-041/T1/01NVb-003-041-1 echo.mp4', '/01NVb-003-045/T3/01NVb-003-045-3 echo.mp4', '/01NVb-003-043/T1/01NVb-003-043-1 echo.mp4', '/01NVb-003-040/T1/01NVb-003-040-1 echo.mp4', '/01NVb-003-042/T3/01NVb-003-042-3 echo.mp4', '/01NVb-003-042/T2/01NVb-003-042-2 echo.mp4', '/01NVb-003-044/T1/01NVb-003-044-2 echo.mp4', '/01NVb-003-042/T1/01NVb-003-042-1 echo.mp4', '/01NVb-003-041/T3/01NVb-003-041-3 echo.mp4', '/01NVb-003-041/T2/01NVb-003-041-2 echo.mp4', '/01NVb-003-043/T3/01NVb-003-043-3 echo.mp4', '/01NVb-003-043/T1/01NVb-003-043-2 echo.mp4', '/01NVb-003-045/T1/01NVb-003-045-1 echo.mp4', '/01NVb-003-044/T3/01NVb-003-044-3 echo.mp4')\n",
      "======= label_filenames: ('/01NVb-003-040/T2/01nvb-003-040-2-4cv.json', '/01NVb-003-045/T2/01nvb-003-045-2-4cv.json', '/01NVb-003-041/T1/01nvb-003-041-1-4cv.json', '/01NVb-003-045/T3/01nvb-003-045-3-4cv.json', '/01NVb-003-043/T1/01nvb-003-043-1-4cv.json', '/01NVb-003-040/T1/01nvb-003-040-1-4cv.json', '/01NVb-003-042/T3/01nvb-003-042-3-4cv.json', '/01NVb-003-042/T2/01nvb-003-042-2-4cv.json', '/01NVb-003-044/T1/01nvb-003-044-2-4cv.json', '/01NVb-003-042/T1/01nvb-003-042-1-4cv.json', '/01NVb-003-041/T3/01nvb-003-041-3-4cv.json', '/01NVb-003-041/T2/01nvb-003-041-2-4cv.json', '/01NVb-003-043/T3/01nvb-003-043-3-4cv.json', '/01NVb-003-043/T1/01nvb-003-043-2-4cv.json', '/01NVb-003-045/T1/01nvb-003-045-1-4cv.json', '/01NVb-003-044/T3/01nvb-003-044-3-4cv.json')\n",
      "---------------------------------------------\n",
      "==TRAIN_len = 11\n",
      "== video_filenames_train: ('/01NVb-003-040/T2/01NVb-003-040-2 echo.mp4', '/01NVb-003-045/T2/01NVB-003-045-2 echo.mp4', '/01NVb-003-041/T1/01NVb-003-041-1 echo.mp4', '/01NVb-003-045/T3/01NVb-003-045-3 echo.mp4', '/01NVb-003-043/T1/01NVb-003-043-1 echo.mp4', '/01NVb-003-040/T1/01NVb-003-040-1 echo.mp4', '/01NVb-003-042/T3/01NVb-003-042-3 echo.mp4', '/01NVb-003-042/T2/01NVb-003-042-2 echo.mp4', '/01NVb-003-044/T1/01NVb-003-044-2 echo.mp4', '/01NVb-003-042/T1/01NVb-003-042-1 echo.mp4', '/01NVb-003-041/T3/01NVb-003-041-3 echo.mp4')\n",
      "== label_filenames_train: ('/01NVb-003-040/T2/01nvb-003-040-2-4cv.json', '/01NVb-003-045/T2/01nvb-003-045-2-4cv.json', '/01NVb-003-041/T1/01nvb-003-041-1-4cv.json', '/01NVb-003-045/T3/01nvb-003-045-3-4cv.json', '/01NVb-003-043/T1/01nvb-003-043-1-4cv.json', '/01NVb-003-040/T1/01nvb-003-040-1-4cv.json', '/01NVb-003-042/T3/01nvb-003-042-3-4cv.json', '/01NVb-003-042/T2/01nvb-003-042-2-4cv.json', '/01NVb-003-044/T1/01nvb-003-044-2-4cv.json', '/01NVb-003-042/T1/01nvb-003-042-1-4cv.json', '/01NVb-003-041/T3/01nvb-003-041-3-4cv.json')\n",
      "---------------------------------------------\n",
      "  TEST_len = 2\n",
      "== video_filenames_test: ('/01NVb-003-041/T2/01NVb-003-041-2 echo.mp4', '/01NVb-003-043/T3/01NVb-003-043-3 echo.mp4')\n",
      "== label_filenames_test: ('/01NVb-003-041/T2/01nvb-003-041-2-4cv.json', '/01NVb-003-043/T3/01nvb-003-043-3-4cv.json')\n",
      "---------------------------------------------\n",
      "  VALIDATION_len = 3\n",
      "== video_filenames_validation: ('/01NVb-003-043/T1/01NVb-003-043-2 echo.mp4', '/01NVb-003-045/T1/01NVb-003-045-1 echo.mp4', '/01NVb-003-044/T3/01NVb-003-044-3 echo.mp4')\n",
      "== label_filenames_validation: ('/01NVb-003-043/T1/01nvb-003-043-2-4cv.json', '/01NVb-003-045/T1/01nvb-003-045-1-4cv.json', '/01NVb-003-044/T3/01nvb-003-044-3-4cv.json')\n",
      "Files were successfully written at /home/mx19/repositories/echocardiography/scripts/config_files/data_lists/\n"
     ]
    }
   ],
   "source": [
    "START_TIME_OF_THE_NOTEBOOK = time.time()\n",
    "print(f'Starting time of the notebook {START_TIME_OF_THE_NOTEBOOK}')\n",
    "\n",
    "##############################\n",
    "##### Setting up and Checking up device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #or \"cuda:NN\" can also be used e.g., \"cuda:0\"\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "TRAIN_VERSION='train00'\n",
    "# TRAIN_VERSION='train01'\n",
    "# TRAIN_VERSION='train02'\n",
    "\n",
    "TRAINING_SPLITTING = 0.70 #config['ntraining'] #Default\n",
    "TEST_FRACTION = 0.15\n",
    "VAL_FRACTION = 1-TRAINING_SPLITTING-TEST_FRACTION\n",
    "print(f'train_set_size  {TRAINING_SPLITTING}, test_set_size {TEST_FRACTION}, val_test_size {VAL_FRACTION}')\n",
    "FLAG_RANDOMISE_DATA=True #config['randomise_file_list'] #Default\n",
    "\n",
    "### Trump et al. 2022 \n",
    "##\"We trained the models on 55487 images from 1145 individual echocardiograms (appendix pp 2–3).\" \n",
    "##Appendix pp 2–3.\n",
    "##AC4: TRAINING: total videos 740 total frames 9615; T\n",
    "##      TESTING: total videos:64 total frames 1218                \n",
    "\n",
    "\n",
    "##############################\n",
    "## Setting ECHODATASET_PATH; \n",
    "#ECHODATASET_PATH = config['echodataset_path'] # Default\n",
    "\n",
    "ECHODATASET_PATH = '/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects'    \n",
    "### Different script run\n",
    "## class_distribution(train_dataset): {'BKGR': 18, '4CV': 18}\n",
    "## class_distribution(test_dataset): {'BKGR': 5, '4CV': 5}\n",
    "## class_distribution(val_dataset): {'BKGR': 10, '4CV': 10}\n",
    "## Number of frames for training datasets 2160\n",
    "## Number of frames for testing datasets 600\n",
    "## Number of frames for Validation datasets 1200    \n",
    "### Different script run\n",
    "## class_distribution(train_dataset): {'BKGR': 20, '4CV': 20}\n",
    "## class_distribution(test_dataset): {'BKGR': 5, '4CV': 5}\n",
    "## class_distribution(val_dataset): {'BKGR': 8, '4CV': 8}\n",
    "## Number of frames for training datasets 1200\n",
    "## Number of frames for testing datasets 300\n",
    "## Number of frames for Validation datasets 480\n",
    "\n",
    "#ECHODATASET_PATH = '/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-10-subjects'\n",
    "    #\"BATCH_SIZE_OF_CLIPS\": 20,\n",
    "    #\"FRAMES_PER_CLIP\": 1,\n",
    "    #\"Train Dataset Size\": 1280,\n",
    "    #\"Test Dataset Size\": 560,\n",
    "    #\"Validation Dataset Size\": 440,\n",
    "\n",
    "# ECHODATASET_PATH = '/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-20-subjects'\n",
    "    #\"BATCH_SIZE_OF_CLIPS\": 20,\n",
    "    #\"FRAMES_PER_CLIP\": 1,\n",
    "    #\"Train Dataset Size\": 2240,\n",
    "    #\"Test Dataset Size\": 960,\n",
    "    #\"Validation Dataset Size\": 720,\n",
    "\n",
    "# ECHODATASET_PATH = '/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-31-subjects'\n",
    "## class_distribution(train_dataset): {'BKGR': 110, '4CV': 110}\n",
    "## class_distribution(test_dataset): {'BKGR': 17, '4CV': 17}\n",
    "## class_distribution(val_dataset): {'BKGR': 27, '4CV': 27}\n",
    "## Number of frames for training datasets 6600\n",
    "## Number of frames for testing datasets 1020\n",
    "## Number of frames for Validation datasets 1620\n",
    "\n",
    "\n",
    "# ECHODATASET_PATH = '/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-33-subjects'\n",
    "#     #\"BATCH_SIZE_OF_CLIPS\": ?,\n",
    "#     #\"FRAMES_PER_CLIP\": ?,\n",
    "#     #\"Train Dataset Size\": ?,\n",
    "#     #\"Test Dataset Size\": ?,\n",
    "#     #\"Validation Dataset Size\": ?,\n",
    "    \n",
    "    \n",
    "split_train_validate_sets(  \n",
    "                        ECHODATASET_PATH, #config['echodataset_path']\n",
    "                        config['data_list_output_path'], \n",
    "                        TRAINING_SPLITTING,\n",
    "                        TEST_FRACTION,\n",
    "                        FLAG_RANDOMISE_DATA\n",
    "                        )\n",
    "\n",
    "# PRETRANSFORM_IM_SIZE = [64, 64] #[650, 690] original pixel size for VenueGO\n",
    "PRETRANSFORM_IM_SIZE = [128, 128] #[650, 690] original pixel size for VenueGO #for ML4H2022\n",
    "# PRETRANSFORM_IM_SIZE = [256, 256] #[650, 690] original pixel size for VenueGO\n",
    "# PRETRANSFORM_IM_SIZE = [512, 512] #[650, 690] original pixel size for VenueGO #tested with ShrapML_replication_v00\n",
    "# PRETRANSFORM_IM_SIZE = config['pretransform_im_size'] ##DEFAULT\n",
    "\n",
    "### >> CHANGE DENSE LAYER FEATURES IN VGG3D\n",
    "### >> `self.fc0 = nn.Linear(in_features=4194304, out_features=500) #128x128`\n",
    "\n",
    "##############################\n",
    "##### Experiments for Basic HYPERPARAMETER Heuristics \n",
    "\n",
    "#### TESTS\n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 1\n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 2 \n",
    "NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 5; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 15; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 20; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 30; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 40; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 50; \n",
    "# NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 60; \n",
    "\n",
    "\n",
    "# BATCH_SIZE_OF_CLIPS = 1; \n",
    "# BATCH_SIZE_OF_CLIPS = 2;\n",
    "# BATCH_SIZE_OF_CLIPS = 3;\n",
    "# BATCH_SIZE_OF_CLIPS = 4; \n",
    "# BATCH_SIZE_OF_CLIPS = 5; \n",
    "BATCH_SIZE_OF_CLIPS = 10; \n",
    "# BATCH_SIZE_OF_CLIPS = 20; \n",
    "# BATCH_SIZE_OF_CLIPS = 25; \n",
    "# BATCH_SIZE_OF_CLIPS = 30; \n",
    "# BATCH_SIZE_OF_CLIPS = 40;\n",
    "# BATCH_SIZE_OF_CLIPS = 50; \n",
    "# BATCH_SIZE_OF_CLIPS = 60; \n",
    "# BATCH_SIZE_OF_CLIPS = 120; \n",
    "\n",
    "\n",
    "#LEARNING_RATE= 0.00005; \n",
    "\n",
    "\n",
    "#################  LEARNING_RATE \n",
    "### EXPERIMENT 01,02,03,04\n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 1; BATCH_SIZE_OF_CLIPS = 20; LEARNING_RATE= 0.00005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 20; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 20; LEARNING_RATE= 0.0000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 20; LEARNING_RATE= 0.00000005; \n",
    "\n",
    "#################  BATCH_SIZE_OF_CLIPS with LEARNING_RATE= 0.000005 as it is the best peformance of prevous LRs \n",
    "### EXPERIMENT 04,06,07,08\n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 2; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 5; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 10; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10; BATCH_SIZE_OF_CLIPS = 15; LEARNING_RATE= 0.000005; \n",
    "\n",
    "#################  NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP with LEARNING_RATE= 0.000005 and BATCH_SIZE_OF_CLIPS=10\n",
    "### EXPERIMENT 09,10,11,12\n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 2; BATCH_SIZE_OF_CLIPS = 10; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 7; BATCH_SIZE_OF_CLIPS = 10; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 13; BATCH_SIZE_OF_CLIPS = 10; LEARNING_RATE= 0.000005; \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 20; BATCH_SIZE_OF_CLIPS = 10; LEARNING_RATE= 0.000005; \n",
    "\n",
    "##TOADD\n",
    "### * NUMBER_OF_FRAMES_AND PARTICPANTS\n",
    "### * OPTIMISERS \n",
    "\n",
    "# LEARNING_RATE =Trial and Error with diffent values  0.00005; 0.0005; 0.005 and 0.000001; 0.00001; 0.0001; 0.001  \n",
    "\n",
    "\n",
    "# MAX_EPOCHS = 100 #Alternatvely, make use of: config['max_epochs']\n",
    "# MAX_EPOCHS = 150 #Alternatvely, make use of: config['max_epochs']\n",
    "# MAX_EPOCHS = 250 #lternatvely, make use of: config['max_epochs']\n",
    "MAX_EPOCHS = 500 #Alternatvely, make use of: config['max_epochs']\n",
    "\n",
    "\n",
    "##############################\n",
    "##### Setting up animation\n",
    "interval_between_frames_in_milliseconds=33.3 ## 1/30=0.033333\n",
    "frame_per_seconds_for_animated_frames=30\n",
    "\n",
    "\n",
    "#SUBJECT_ID = '073'\n",
    "#print(SUBJECT_ID)\n",
    "\n",
    "### CUDA out of memory \n",
    "#NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP = 10\n",
    "#PRETRANSFORM_IM_SIZE = [128, 128] \n",
    "#RuntimeError: CUDA out of memory. Tried to allocate 7.81 GiB (GPU 0; 15.74 GiB total capacity; 8.51 GiB already allocated; 5.05 GiB free; 8.53 GiB reserved in total by PyTorch)\n",
    "## REBOOT MACHINE\n",
    "#RuntimeError: CUDA out of memory. Tried to allocate 7.81 GiB (GPU 0; 15.74 GiB total capacity; 8.51 GiB already allocated; 5.13 GiB free; 8.53 GiB reserved in total by PyTorch)\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "## Setting labels\n",
    "label_id = ('BKGR', '4CV')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e424e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:06.154451Z",
     "start_time": "2022-08-31T12:16:06.040686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-040/T2/01NVb-003-040-2 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97114679618872 nframes=26836 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-045/T2/01NVB-003-045-2 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97203398407009 nframes=14956 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-041/T1/01NVb-003-041-1 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.36164397750906 nframes=18822 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-045/T3/01NVb-003-045-3 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.971736011469602 nframes=17568 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-043/T1/01NVb-003-043-1 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97199599141347 nframes=15245 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-040/T1/01NVb-003-040-1 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.971632559729454 nframes=18702 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-042/T3/01NVb-003-042-3 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.972288279876253 nframes=13272 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-042/T2/01NVb-003-042-2 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.972611145636726 nframes=11612 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-044/T1/01NVb-003-044-2 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97213741887112 nframes=14222 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-042/T1/01NVb-003-042-1 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.971431814361793 nframes=21380 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-041/T3/01NVb-003-041-3 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97287612672228 nframes=10531 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-041/T2/01NVb-003-041-2 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97271017303212 nframes=11183 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-043/T3/01NVb-003-043-3 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.962891699226105 nframes=8395 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-043/T1/01NVb-003-043-2 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.971971788739964 nframes=15435 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-045/T1/01NVb-003-045-1 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.972716660300705 nframes=11156 \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  VIDEO_FEATURES\n",
      "    video_name=/media/mx19/vitaluskcl/datasets/echocardiography/videos-echo-annotated-05-subjects//01NVb-003-044/T3/01NVb-003-044-3 echo.mp4\n",
      "    Frame_height=1080, frame_width=1920 fps=29.97189215655725 nframes=16095 \n",
      "  \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Defining transforms that apply to the entire dataset.\n",
    "# These transforms are not augmentation.\n",
    "if config['use_pretransform_image_size']:\n",
    "    pretransform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(size=PRETRANSFORM_IM_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "else:\n",
    "    pretransform = None\n",
    "    \n",
    "    #config['use_train_augmentation']#Default\n",
    "    \n",
    "    \n",
    "# These transforms have random parameters changing at each epoch.\n",
    "if config['use_train_augmentation']:\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=5),  # in degrees\n",
    "        transforms.RandomEqualize(p=0.5),\n",
    "        transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(), \n",
    "    ])\n",
    "else:\n",
    "    transform = None\n",
    "    \n",
    "    \n",
    "# These transforms have random parameters changing at each epoch.\n",
    "if config['use_validation_augmentation']:\n",
    "    val_transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomRotation(degrees=5),  # in degrees\n",
    "    #transforms.RandomEqualize(p=0.5),\n",
    "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    #transforms.ToTensor(), \n",
    "    ])\n",
    "else:\n",
    "    transform = None\n",
    "\n",
    "\n",
    "train_dataset = EchoClassesDataset(\n",
    "    echodataset_path=ECHODATASET_PATH,\n",
    "    temporal_data_path=config['temporal_data_path'],\n",
    "    participant_videos_list=config['participant_videos_list_train'],\n",
    "    participant_path_json_list=config['participant_path_json_list_train'],\n",
    "    crop_bounds_for_us_image=config['crop_bounds_for_us_image'],\n",
    "    pretransform_im_size=PRETRANSFORM_IM_SIZE,\n",
    "    pretransform=pretransform,\n",
    "    number_of_frames_per_segment_in_a_clip=NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP, #config['number_of_frames_per_segment_in_a_clip'],\n",
    "    sliding_window_length_in_percentage_of_frames_per_segment=config['sliding_window_length_in_percentage_of_frames_per_segment'],\n",
    "    device=DEVICE,\n",
    "    max_background_duration_in_secs=config['max_background_duration_in_secs'],\n",
    "    transform=train_transform, #None,#transform=train_transform,\n",
    "    use_tmp_storage=config['use_tmp_storage']\n",
    "    )\n",
    "\n",
    "test_dataset = EchoClassesDataset(\n",
    "    echodataset_path=ECHODATASET_PATH,\n",
    "    temporal_data_path=config['temporal_data_path'],\n",
    "    participant_videos_list=config['participant_videos_list_test'],\n",
    "    participant_path_json_list=config['participant_path_json_list_test'],\n",
    "    crop_bounds_for_us_image=config['crop_bounds_for_us_image'],\n",
    "    pretransform_im_size=PRETRANSFORM_IM_SIZE,\n",
    "    pretransform=pretransform,\n",
    "    number_of_frames_per_segment_in_a_clip=NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP, #config['number_of_frames_per_segment_in_a_clip'],\n",
    "    sliding_window_length_in_percentage_of_frames_per_segment=config['sliding_window_length_in_percentage_of_frames_per_segment'],\n",
    "    device=DEVICE,\n",
    "    max_background_duration_in_secs=config['max_background_duration_in_secs'],\n",
    "    transform=None,#transform=test_transform,\n",
    "    use_tmp_storage=config['use_tmp_storage']\n",
    "    )\n",
    "\n",
    "val_dataset = EchoClassesDataset(\n",
    "    echodataset_path=ECHODATASET_PATH,\n",
    "    temporal_data_path=config['temporal_data_path'],\n",
    "    participant_videos_list=config['participant_videos_list_validation'],\n",
    "    participant_path_json_list=config['participant_path_json_list_validation'],\n",
    "    crop_bounds_for_us_image=config['crop_bounds_for_us_image'],\n",
    "    pretransform_im_size=PRETRANSFORM_IM_SIZE,\n",
    "    pretransform=pretransform,\n",
    "    number_of_frames_per_segment_in_a_clip=NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP, #config['number_of_frames_per_segment_in_a_clip'],\n",
    "    sliding_window_length_in_percentage_of_frames_per_segment=config['sliding_window_length_in_percentage_of_frames_per_segment'],\n",
    "    device=DEVICE,\n",
    "    max_background_duration_in_secs=config['max_background_duration_in_secs'],\n",
    "    transform=None,#transform=val_transform,\n",
    "    use_tmp_storage=config['use_tmp_storage']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4760906",
   "metadata": {},
   "source": [
    "## 3. Plotting Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6472a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:51.402673Z",
     "start_time": "2022-08-31T12:16:06.155339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mx19/anaconda3/envs/rt-ai-echo-VE/lib/python3.8/site-packages/torchvision/transforms/functional.py:594: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
      "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
      "To get the qr decomposition consider using torch.linalg.qr.\n",
      "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
      "The unpacking of the solution, as in\n",
      "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
      "should be replaced with\n",
      "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /tmp/pip-req-build-pma2oi4d/aten/src/ATen/LegacyTHFunctionsCPU.cpp:389.)\n",
      "  res = torch.lstsq(b_matrix, a_matrix)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_distribution(train_dataset): {'BKGR': 24, '4CV': 24}\n",
      "class_distribution(test_dataset): {'BKGR': 4, '4CV': 4}\n",
      "class_distribution(val_dataset): {'BKGR': 5, '4CV': 5}\n",
      "Number of frames for training datasets 240\n",
      "Number of frames for testing datasets 40\n",
      "Number of frames for Validation datasets 50\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_class_dict = get_class_distribution(train_dataset,label_id)\n",
    "test_set_class_dict = get_class_distribution(test_dataset,label_id)\n",
    "val_set_class_dict = get_class_distribution(val_dataset,label_id)\n",
    "\n",
    "print(f'class_distribution(train_dataset): {train_set_class_dict}')\n",
    "print(f'class_distribution(test_dataset): {test_set_class_dict}')\n",
    "print(f'class_distribution(val_dataset): {val_set_class_dict}' )\n",
    "    \n",
    "#number_of_frames_per_segment_in_a_clip = config['number_of_frames_per_segment_in_a_clip']    \n",
    "print(f'Number of frames for training datasets {len(train_dataset)*NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP}')\n",
    "print(f'Number of frames for testing datasets {len(test_dataset)*NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP}')\n",
    "print(f'Number of frames for Validation datasets {len(val_dataset)*NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP}')\n",
    "\n",
    "plot_title_train_label= f'TRAIN dataset of {len(train_dataset)} clips with {NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP} n_frames_per_clip'\n",
    "plot_title_test_label= f'TEST dataset of {len(test_dataset)} clips with {NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP} n_frames_per_clip'\n",
    "plot_title_val_label= f'VALIDATION dataset of {len(val_dataset)} clips with {NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP} n_frames_per_clip'\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,7))\n",
    "plot_from_dict(train_set_class_dict, plot_title=plot_title_train_label, ax=axes[0])\n",
    "plot_from_dict(val_set_class_dict, plot_title=plot_title_test_label, ax=axes[1])\n",
    "plot_from_dict(test_set_class_dict, plot_title=plot_title_val_label, ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f6d225",
   "metadata": {},
   "source": [
    "## 5. Displayting frames in the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d8805e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:51.626168Z",
     "start_time": "2022-08-31T12:16:51.403734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "train_dataset.__len__() = 48\n",
      "====================================================\n",
      "len(train_dataloader): 5 BATCHES of BATCH_SIZE_OF_CLIPS 10\n",
      "  ====================================================\n",
      "    BATCH_OF_CLIPS_INDEX : 0 / 4\n",
      "    sample_batched_labels.size(): torch.Size([10])\n",
      "    sample_batched_labels.squeeze().size(): torch.Size([10])\n",
      "    sample_batched_images.size(): torch.Size([10, 1, 5, 128, 128])\n",
      "        BATCH_SIZE_IDX 0 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 1 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 2 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 3 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 4 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 5 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 6 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 7 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 8 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 9 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "  ====================================================\n",
      "    BATCH_OF_CLIPS_INDEX : 1 / 4\n",
      "    sample_batched_labels.size(): torch.Size([10])\n",
      "    sample_batched_labels.squeeze().size(): torch.Size([10])\n",
      "    sample_batched_images.size(): torch.Size([10, 1, 5, 128, 128])\n",
      "        BATCH_SIZE_IDX 0 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 1 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 2 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 3 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 4 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 5 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 6 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 7 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 8 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 9 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "  ====================================================\n",
      "    BATCH_OF_CLIPS_INDEX : 2 / 4\n",
      "    sample_batched_labels.size(): torch.Size([10])\n",
      "    sample_batched_labels.squeeze().size(): torch.Size([10])\n",
      "    sample_batched_images.size(): torch.Size([10, 1, 5, 128, 128])\n",
      "        BATCH_SIZE_IDX 0 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 1 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 2 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 3 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 4 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 5 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 6 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 7 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 8 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 9 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "  ====================================================\n",
      "    BATCH_OF_CLIPS_INDEX : 3 / 4\n",
      "    sample_batched_labels.size(): torch.Size([10])\n",
      "    sample_batched_labels.squeeze().size(): torch.Size([10])\n",
      "    sample_batched_images.size(): torch.Size([10, 1, 5, 128, 128])\n",
      "        BATCH_SIZE_IDX 0 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 1 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 2 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 3 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 4 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 5 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 6 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 7 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 8 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 9 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "  ====================================================\n",
      "    BATCH_OF_CLIPS_INDEX : 4 / 4\n",
      "    sample_batched_labels.size(): torch.Size([8])\n",
      "    sample_batched_labels.squeeze().size(): torch.Size([8])\n",
      "    sample_batched_images.size(): torch.Size([8, 1, 5, 128, 128])\n",
      "        BATCH_SIZE_IDX 0 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 1 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 2 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 3 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 4 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 5 \n",
      "          label: 1\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 6 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "        BATCH_SIZE_IDX 7 \n",
      "          label: 0\n",
      "          Sample_batched_idx_image.size()  torch.Size([1, 5, 128, 128])\n",
      "          Grid size torch.Size([5, 128, 128])\n",
      "====================================================\n",
      " test_dataset.__len__() = 8\n",
      "====================================================\n",
      " validation_dataset.__len__() = 10\n"
     ]
    }
   ],
   "source": [
    "print(f'====================================================')\n",
    "print(f'train_dataset.__len__() = {train_dataset.__len__()}')\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE_OF_CLIPS, \n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "\n",
    "\n",
    "print(f'====================================================')\n",
    "print(f'len(train_dataloader): {len(train_dataloader)} BATCHES of BATCH_SIZE_OF_CLIPS {BATCH_SIZE_OF_CLIPS}')\n",
    "for clip_batch_idx, sample_batched in enumerate(train_dataloader):\n",
    "    print(f'  ====================================================')\n",
    "    sample_batched_images=sample_batched[0]\n",
    "    sample_batched_labels=sample_batched[1]\n",
    "    print(f'    BATCH_OF_CLIPS_INDEX : {clip_batch_idx} / {len(train_dataloader) - 1}')\n",
    "    print(f'    sample_batched_labels.size(): {  sample_batched_labels.size()  }')\n",
    "    print(f'    sample_batched_labels.squeeze().size(): {  sample_batched_labels.squeeze().size()  }')\n",
    "    print(f'    sample_batched_images.size(): {sample_batched_images.size()}')\n",
    "\n",
    "    for BATCH_SIZE_IDX, label in enumerate(sample_batched_labels):\n",
    "        print(f'        BATCH_SIZE_IDX {BATCH_SIZE_IDX} ')\n",
    "        print(f'          label: {label}')\n",
    "        sample_batched_idx_image = sample_batched_images[BATCH_SIZE_IDX,...]\n",
    "        print(f'          Sample_batched_idx_image.size()  {sample_batched_idx_image.size() }'  )\n",
    "\n",
    "        grid = utils.make_grid(sample_batched_idx_image)\n",
    "        print(f'          Grid size {grid.size()}' )\n",
    "#         plt.figure(figsize =(20,20) )\n",
    "#         plt.imshow( grid.cpu().detach().numpy().transpose(1, 2, 0) )\n",
    "#         plt.title(f'BATCH_SIZE_IDX {BATCH_SIZE_IDX}; Label: {label_id[label]}')\n",
    "#         plt.axis('off')\n",
    "#         plt.ioff()\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "print(f'====================================================')\n",
    "print(f' test_dataset.__len__() = {test_dataset.__len__()}')\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE_OF_CLIPS, \n",
    "    shuffle=True, \n",
    "    num_workers=0)\n",
    "\n",
    "print(f'====================================================')\n",
    "print(f' validation_dataset.__len__() = {val_dataset.__len__()}')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE_OF_CLIPS, \n",
    "    shuffle=True, \n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e92336",
   "metadata": {},
   "source": [
    "## 6. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e369a416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:53.657529Z",
     "start_time": "2022-08-31T12:16:51.626990Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "model=basicVGG2D_04layers(in_channels=NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP,\n",
    "                 num_classes=2,\n",
    "                 n_frames_per_clip=NUMBER_OF_FRAMES_PER_SEGMENT_IN_A_CLIP\n",
    "                )        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aafb41",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Print Model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc693127",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:55.415621Z",
     "start_time": "2022-08-31T12:16:53.658596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "basicVGG2D_04layers(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc0): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=131072, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "====================================================\n",
      "layer1.0.weight tensor([[[[ 4.0179e-02,  8.8382e-02, -5.3442e-02],\n",
      "          [-1.0625e-01, -1.1535e-01, -1.2727e-01],\n",
      "          [ 1.6011e-02, -6.9701e-02,  4.1523e-02]],\n",
      "\n",
      "         [[ 1.1625e-01, -1.1388e-01,  3.3283e-02],\n",
      "          [ 9.2518e-02, -9.8437e-02,  1.1418e-01],\n",
      "          [-1.5943e-02,  2.8238e-02,  5.5597e-02]],\n",
      "\n",
      "         [[-1.1803e-01,  8.4627e-02,  2.1388e-02],\n",
      "          [-9.8308e-02,  8.6940e-02, -5.5647e-02],\n",
      "          [ 1.1078e-01,  1.5587e-02, -5.2945e-02]],\n",
      "\n",
      "         [[-1.9988e-02, -6.5610e-02,  1.0785e-01],\n",
      "          [-1.8183e-02, -9.7427e-02, -2.9577e-02],\n",
      "          [ 3.8373e-02, -1.2029e-01,  1.0746e-01]],\n",
      "\n",
      "         [[ 1.9890e-02, -1.9551e-02, -2.6027e-02],\n",
      "          [ 8.5721e-02,  1.1270e-01, -1.2547e-01],\n",
      "          [ 9.6644e-03, -6.4300e-02, -1.0316e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8423e-02, -4.9853e-02, -9.3899e-02],\n",
      "          [ 2.3310e-02, -1.2658e-01,  7.4409e-02],\n",
      "          [ 1.7508e-02, -9.8234e-02, -1.1604e-01]],\n",
      "\n",
      "         [[ 8.6357e-03,  1.0961e-01,  1.3038e-01],\n",
      "          [-1.3381e-01,  9.8385e-02,  8.1933e-02],\n",
      "          [-1.2907e-01, -3.6583e-02, -6.1521e-02]],\n",
      "\n",
      "         [[ 7.3941e-02,  1.1172e-02, -1.4738e-02],\n",
      "          [ 6.9474e-02,  9.9687e-02,  1.1200e-02],\n",
      "          [-8.0711e-02, -1.8147e-02, -2.2919e-02]],\n",
      "\n",
      "         [[-7.7626e-02, -1.1435e-01, -1.6820e-02],\n",
      "          [-1.2782e-01, -5.2948e-02, -4.6654e-02],\n",
      "          [-1.1050e-01, -2.4079e-02, -3.4728e-02]],\n",
      "\n",
      "         [[ 6.9677e-02, -1.1516e-01, -1.1451e-01],\n",
      "          [-3.0135e-02, -9.8946e-02, -9.4177e-02],\n",
      "          [-8.6358e-02,  7.9005e-02, -1.1579e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1681e-01,  1.3416e-02,  7.1604e-02],\n",
      "          [-1.0256e-01,  2.0800e-02, -9.4751e-02],\n",
      "          [-4.1309e-02, -8.4145e-02, -2.2617e-02]],\n",
      "\n",
      "         [[ 8.8910e-02,  9.5092e-02,  2.0221e-03],\n",
      "          [ 3.2253e-03, -4.2694e-02,  7.0078e-02],\n",
      "          [ 7.6996e-02,  4.1545e-03,  7.3835e-02]],\n",
      "\n",
      "         [[-3.0244e-02,  8.6546e-02,  6.4776e-03],\n",
      "          [ 7.4066e-02, -9.7899e-02,  3.2036e-02],\n",
      "          [ 7.6310e-02,  2.5691e-02,  7.7531e-02]],\n",
      "\n",
      "         [[ 1.3572e-01, -1.1653e-01, -2.3009e-02],\n",
      "          [ 5.0008e-02,  7.6256e-02, -3.2547e-03],\n",
      "          [ 1.1698e-01,  5.7852e-02, -1.1180e-02]],\n",
      "\n",
      "         [[ 1.6283e-02, -6.6649e-02,  1.2914e-02],\n",
      "          [-1.1467e-01,  1.1220e-01,  5.4317e-02],\n",
      "          [-8.5070e-02,  7.3451e-02,  1.0475e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.2318e-01, -1.1097e-01, -2.4031e-02],\n",
      "          [ 1.2841e-01,  1.9141e-03, -1.0648e-01],\n",
      "          [-9.6278e-02, -2.2350e-02, -1.4950e-02]],\n",
      "\n",
      "         [[-9.0498e-02,  4.8186e-02,  9.4446e-05],\n",
      "          [-7.7505e-02, -9.4125e-02,  1.0622e-01],\n",
      "          [-1.2034e-01,  4.8919e-02,  1.2502e-01]],\n",
      "\n",
      "         [[-2.6474e-02, -3.5589e-02,  4.6878e-02],\n",
      "          [-3.3282e-02, -9.6866e-02,  1.1220e-01],\n",
      "          [ 1.2376e-01, -4.5556e-02,  9.8426e-02]],\n",
      "\n",
      "         [[ 1.0915e-01, -1.0799e-01,  3.1933e-03],\n",
      "          [-8.5113e-02,  2.6100e-02, -1.2672e-02],\n",
      "          [-3.6019e-02,  1.3074e-01, -9.7425e-02]],\n",
      "\n",
      "         [[ 9.1014e-02, -9.5217e-02,  7.5042e-02],\n",
      "          [ 8.7403e-02,  7.1738e-03,  1.0728e-01],\n",
      "          [-3.7021e-02,  8.6636e-02, -4.6122e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0013e-01, -9.3068e-02, -1.1843e-01],\n",
      "          [ 6.1229e-02,  3.7926e-02, -9.2075e-02],\n",
      "          [-1.0561e-01,  1.3397e-02, -6.1846e-02]],\n",
      "\n",
      "         [[-1.0151e-01, -1.1396e-01,  1.1127e-01],\n",
      "          [ 1.7385e-02,  1.1977e-01, -4.6249e-02],\n",
      "          [-7.6849e-02,  9.0929e-02,  7.3752e-02]],\n",
      "\n",
      "         [[ 6.2185e-02, -2.3825e-02, -7.3341e-02],\n",
      "          [ 1.1598e-01, -5.6927e-02, -1.0180e-01],\n",
      "          [-3.1939e-02, -1.3419e-01,  9.9047e-02]],\n",
      "\n",
      "         [[-1.3863e-01,  4.8383e-02,  3.7254e-02],\n",
      "          [-8.4455e-02,  9.1726e-02,  8.1500e-03],\n",
      "          [ 1.1502e-01, -1.1080e-01,  9.2419e-02]],\n",
      "\n",
      "         [[ 9.5391e-02, -4.7563e-02,  1.1802e-01],\n",
      "          [-6.1413e-02, -6.7316e-02, -9.0627e-02],\n",
      "          [ 8.3373e-02, -1.2345e-01, -7.1857e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0896e-02,  9.0589e-02,  1.1942e-02],\n",
      "          [-9.6598e-02, -2.2601e-02, -6.9420e-02],\n",
      "          [ 6.6372e-04, -1.0417e-01, -8.8877e-02]],\n",
      "\n",
      "         [[-1.1769e-01,  2.3918e-02,  9.6634e-02],\n",
      "          [ 6.0452e-03, -7.4322e-03, -2.8439e-02],\n",
      "          [ 2.1470e-02,  1.4203e-02,  8.6796e-02]],\n",
      "\n",
      "         [[ 2.7782e-02,  3.4521e-02,  7.0673e-02],\n",
      "          [ 4.6878e-02, -1.1767e-01,  1.2550e-01],\n",
      "          [-7.1403e-02, -1.1603e-01, -6.1604e-02]],\n",
      "\n",
      "         [[-6.2563e-02,  5.2488e-02,  8.0839e-02],\n",
      "          [ 9.8230e-02, -9.9572e-02,  1.3077e-01],\n",
      "          [ 1.1792e-01,  6.1621e-02,  9.5612e-05]],\n",
      "\n",
      "         [[-3.4444e-02,  7.1812e-02, -8.2415e-02],\n",
      "          [-1.0485e-01, -6.7264e-02, -1.8404e-02],\n",
      "          [-5.7274e-02, -1.2180e-01, -9.6267e-02]]]], device='cuda:0')\n",
      "layer1.0.bias tensor([-0.1166,  0.0785, -0.1074, -0.0384,  0.1338,  0.1215,  0.0521, -0.0843,\n",
      "         0.0267,  0.0469, -0.0739, -0.1289, -0.0468, -0.0546,  0.0602,  0.0636,\n",
      "        -0.0244, -0.0056,  0.0384, -0.0391, -0.0897, -0.1322, -0.0924,  0.0101,\n",
      "         0.0072,  0.0293, -0.0036,  0.1172, -0.0502, -0.0373, -0.0806, -0.0387,\n",
      "        -0.1268, -0.0931,  0.0869, -0.0445, -0.0699,  0.0777, -0.0893,  0.1280,\n",
      "         0.0696,  0.1317,  0.0189, -0.0803, -0.0582,  0.0691,  0.0477, -0.0468,\n",
      "        -0.0853,  0.0503, -0.0039, -0.1076, -0.0266, -0.0606, -0.1342, -0.0246,\n",
      "         0.0733,  0.1249,  0.0681,  0.0006,  0.0814, -0.0452, -0.1179, -0.1044],\n",
      "       device='cuda:0')\n",
      "layer1.1.weight tensor([0.9046, 0.9043, 0.8988, 0.9057, 0.9052, 0.9042, 0.9167, 0.9117, 0.9055,\n",
      "        0.9001, 0.9045, 0.9009, 0.8978, 0.8969, 0.9138, 0.9053, 0.9017, 0.8975,\n",
      "        0.8975, 0.9046, 0.9023, 0.9013, 0.9052, 0.9075, 0.9053, 0.9008, 0.9102,\n",
      "        0.9048, 0.9000, 0.9056, 0.9053, 0.9076, 0.9146, 0.9055, 0.9246, 0.8990,\n",
      "        0.9223, 0.9060, 0.9003, 0.9016, 0.8997, 0.9066, 0.9012, 0.9069, 0.9007,\n",
      "        0.9064, 0.9068, 0.9043, 0.9050, 0.9056, 0.9055, 0.8970, 0.9229, 0.9050,\n",
      "        0.9079, 0.9068, 0.9071, 0.8986, 0.9037, 0.9062, 0.9045, 0.9066, 0.9048,\n",
      "        0.9050], device='cuda:0')\n",
      "layer1.1.bias tensor([-0.0001, -0.0017, -0.0022, -0.0044, -0.0007,  0.0002, -0.0074,  0.0003,\n",
      "        -0.0018, -0.0019, -0.0031, -0.0080, -0.0024, -0.0029, -0.0077,  0.0002,\n",
      "        -0.0012, -0.0004, -0.0019, -0.0016, -0.0050, -0.0013,  0.0006,  0.0026,\n",
      "         0.0008, -0.0017, -0.0033, -0.0053, -0.0026, -0.0025, -0.0006,  0.0013,\n",
      "        -0.0015, -0.0012, -0.0003, -0.0047, -0.0110,  0.0012, -0.0049, -0.0013,\n",
      "        -0.0028,  0.0041, -0.0101,  0.0036, -0.0081,  0.0036,  0.0031, -0.0015,\n",
      "         0.0012,  0.0013,  0.0024, -0.0010, -0.0016,  0.0010, -0.0021,  0.0017,\n",
      "         0.0040, -0.0017, -0.0025,  0.0026, -0.0035,  0.0019,  0.0009,  0.0038],\n",
      "       device='cuda:0')\n",
      "layer2.0.weight tensor([[[[ 0.0077, -0.0335,  0.0274],\n",
      "          [ 0.0185,  0.0027, -0.0027],\n",
      "          [ 0.0325, -0.0177, -0.0087]],\n",
      "\n",
      "         [[-0.0278, -0.0168, -0.0187],\n",
      "          [ 0.0091,  0.0334, -0.0024],\n",
      "          [ 0.0330,  0.0123, -0.0192]],\n",
      "\n",
      "         [[ 0.0277, -0.0077,  0.0356],\n",
      "          [ 0.0186,  0.0028,  0.0325],\n",
      "          [-0.0353,  0.0331, -0.0047]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0263, -0.0217, -0.0208],\n",
      "          [-0.0334, -0.0290, -0.0084],\n",
      "          [-0.0125, -0.0208, -0.0033]],\n",
      "\n",
      "         [[ 0.0140,  0.0361,  0.0371],\n",
      "          [ 0.0160, -0.0166,  0.0071],\n",
      "          [-0.0210,  0.0273, -0.0363]],\n",
      "\n",
      "         [[ 0.0185,  0.0403,  0.0360],\n",
      "          [-0.0129,  0.0227,  0.0063],\n",
      "          [ 0.0058, -0.0067,  0.0329]]],\n",
      "\n",
      "\n",
      "        [[[-0.0090,  0.0017,  0.0250],\n",
      "          [-0.0281, -0.0029,  0.0079],\n",
      "          [-0.0330, -0.0231, -0.0326]],\n",
      "\n",
      "         [[ 0.0016, -0.0255, -0.0328],\n",
      "          [ 0.0016,  0.0336, -0.0130],\n",
      "          [-0.0092, -0.0086, -0.0368]],\n",
      "\n",
      "         [[ 0.0346,  0.0225,  0.0135],\n",
      "          [ 0.0184,  0.0143, -0.0091],\n",
      "          [ 0.0319, -0.0342,  0.0193]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0356, -0.0288,  0.0041],\n",
      "          [-0.0324, -0.0037, -0.0365],\n",
      "          [ 0.0224, -0.0164,  0.0001]],\n",
      "\n",
      "         [[-0.0317,  0.0098, -0.0275],\n",
      "          [ 0.0200, -0.0217, -0.0281],\n",
      "          [ 0.0009,  0.0270,  0.0141]],\n",
      "\n",
      "         [[-0.0131, -0.0195, -0.0120],\n",
      "          [ 0.0141,  0.0235,  0.0289],\n",
      "          [-0.0131,  0.0098, -0.0114]]],\n",
      "\n",
      "\n",
      "        [[[-0.0175,  0.0330,  0.0103],\n",
      "          [ 0.0071,  0.0336,  0.0041],\n",
      "          [ 0.0255,  0.0244, -0.0123]],\n",
      "\n",
      "         [[-0.0283, -0.0260,  0.0089],\n",
      "          [ 0.0305,  0.0193,  0.0164],\n",
      "          [-0.0337,  0.0364,  0.0298]],\n",
      "\n",
      "         [[-0.0032,  0.0210, -0.0243],\n",
      "          [-0.0181, -0.0197, -0.0005],\n",
      "          [-0.0037, -0.0069,  0.0128]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0167,  0.0018, -0.0049],\n",
      "          [-0.0298, -0.0196,  0.0321],\n",
      "          [-0.0017, -0.0087, -0.0364]],\n",
      "\n",
      "         [[ 0.0202, -0.0327, -0.0352],\n",
      "          [ 0.0020, -0.0364,  0.0302],\n",
      "          [-0.0113, -0.0175, -0.0102]],\n",
      "\n",
      "         [[-0.0178,  0.0353,  0.0020],\n",
      "          [-0.0339, -0.0334,  0.0057],\n",
      "          [-0.0414,  0.0201,  0.0182]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0126,  0.0289,  0.0295],\n",
      "          [-0.0233, -0.0036,  0.0320],\n",
      "          [-0.0225, -0.0029,  0.0130]],\n",
      "\n",
      "         [[-0.0038,  0.0023, -0.0106],\n",
      "          [ 0.0220,  0.0051,  0.0069],\n",
      "          [ 0.0103,  0.0158,  0.0310]],\n",
      "\n",
      "         [[-0.0346, -0.0320, -0.0017],\n",
      "          [ 0.0152,  0.0323,  0.0126],\n",
      "          [ 0.0106, -0.0218,  0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0267,  0.0260, -0.0324],\n",
      "          [ 0.0146,  0.0375,  0.0222],\n",
      "          [ 0.0112, -0.0286, -0.0189]],\n",
      "\n",
      "         [[-0.0314,  0.0098, -0.0370],\n",
      "          [ 0.0027,  0.0029, -0.0008],\n",
      "          [-0.0078,  0.0010,  0.0375]],\n",
      "\n",
      "         [[-0.0186, -0.0183,  0.0012],\n",
      "          [-0.0078,  0.0365, -0.0151],\n",
      "          [-0.0316,  0.0048, -0.0331]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0183,  0.0318, -0.0114],\n",
      "          [-0.0363, -0.0365, -0.0345],\n",
      "          [ 0.0301,  0.0364,  0.0007]],\n",
      "\n",
      "         [[ 0.0092,  0.0275,  0.0013],\n",
      "          [ 0.0163,  0.0329,  0.0023],\n",
      "          [ 0.0140,  0.0159,  0.0308]],\n",
      "\n",
      "         [[ 0.0340,  0.0035, -0.0355],\n",
      "          [-0.0370,  0.0120, -0.0136],\n",
      "          [ 0.0217,  0.0381, -0.0206]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0020, -0.0322,  0.0283],\n",
      "          [-0.0157,  0.0220, -0.0149],\n",
      "          [ 0.0342, -0.0073, -0.0088]],\n",
      "\n",
      "         [[ 0.0001,  0.0001, -0.0098],\n",
      "          [ 0.0145, -0.0326, -0.0042],\n",
      "          [-0.0033,  0.0323, -0.0194]],\n",
      "\n",
      "         [[-0.0198,  0.0372, -0.0051],\n",
      "          [ 0.0171, -0.0287,  0.0322],\n",
      "          [-0.0385,  0.0113, -0.0334]]],\n",
      "\n",
      "\n",
      "        [[[-0.0047,  0.0220,  0.0255],\n",
      "          [-0.0057,  0.0159, -0.0214],\n",
      "          [ 0.0140, -0.0178, -0.0319]],\n",
      "\n",
      "         [[-0.0325, -0.0207,  0.0056],\n",
      "          [ 0.0275,  0.0142, -0.0050],\n",
      "          [-0.0068,  0.0106, -0.0229]],\n",
      "\n",
      "         [[ 0.0190, -0.0152, -0.0356],\n",
      "          [ 0.0328, -0.0166,  0.0247],\n",
      "          [-0.0126,  0.0264, -0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0396, -0.0127,  0.0306],\n",
      "          [-0.0224, -0.0191,  0.0126],\n",
      "          [-0.0346, -0.0311, -0.0228]],\n",
      "\n",
      "         [[ 0.0286,  0.0276, -0.0042],\n",
      "          [ 0.0145,  0.0076,  0.0244],\n",
      "          [-0.0248,  0.0223, -0.0186]],\n",
      "\n",
      "         [[-0.0212, -0.0047, -0.0195],\n",
      "          [-0.0197, -0.0213,  0.0077],\n",
      "          [ 0.0232,  0.0023,  0.0247]]]], device='cuda:0')\n",
      "layer2.0.bias tensor([ 2.0658e-02, -1.6013e-02, -2.7271e-02,  2.7817e-02,  2.9310e-02,\n",
      "         7.5744e-03,  2.2850e-02, -2.0093e-02, -3.0538e-02,  2.2791e-02,\n",
      "         2.0129e-02,  3.1380e-02,  6.9419e-03,  5.9053e-03, -2.2595e-02,\n",
      "         7.2209e-03, -1.1287e-02,  2.3389e-02,  7.1533e-03, -2.2848e-03,\n",
      "        -2.8852e-02,  1.5647e-02, -1.0128e-02,  2.1971e-02, -2.9766e-02,\n",
      "         2.5197e-02, -6.9612e-03, -2.8052e-02, -1.4268e-02,  3.4223e-02,\n",
      "         1.5801e-05,  9.9352e-03,  2.9437e-02,  3.6048e-02,  1.6135e-02,\n",
      "         1.8560e-02, -2.3721e-02,  2.7252e-02,  1.2881e-02,  2.2114e-02,\n",
      "         1.0827e-02,  4.0413e-03, -1.8451e-02, -8.0152e-05, -1.5305e-02,\n",
      "        -3.1918e-02, -1.4277e-02,  3.5097e-02, -2.8565e-02,  1.2435e-02,\n",
      "        -2.0526e-03, -2.4488e-02,  1.6872e-03,  1.2767e-02, -3.4752e-02,\n",
      "         8.1781e-03,  2.6027e-02, -1.2904e-02,  1.5258e-02, -3.6604e-02,\n",
      "         3.1469e-02,  3.2874e-02,  1.1834e-02, -2.6036e-02], device='cuda:0')\n",
      "layer2.1.weight tensor([0.9036, 0.9046, 0.9020, 0.9059, 0.9095, 0.9017, 0.9065, 0.9025, 0.9020,\n",
      "        0.9044, 0.9044, 0.9043, 0.9054, 0.9040, 0.9115, 0.9046, 0.9032, 0.9100,\n",
      "        0.9095, 0.9072, 0.9012, 0.9068, 0.9066, 0.9061, 0.9015, 0.9048, 0.9037,\n",
      "        0.9039, 0.9111, 0.9025, 0.9078, 0.9055, 0.9013, 0.9138, 0.9035, 0.9018,\n",
      "        0.8998, 0.9041, 0.9032, 0.9033, 0.9049, 0.9039, 0.9059, 0.9048, 0.9034,\n",
      "        0.9054, 0.9051, 0.9122, 0.9054, 0.9038, 0.9161, 0.9085, 0.9039, 0.8986,\n",
      "        0.9035, 0.9042, 0.9044, 0.9052, 0.9109, 0.8987, 0.9158, 0.9035, 0.9033,\n",
      "        0.9020], device='cuda:0')\n",
      "layer2.1.bias tensor([-9.7988e-04, -3.4157e-04, -1.0455e-03, -1.9379e-03,  3.3935e-05,\n",
      "        -3.6304e-03,  3.5348e-03, -1.0937e-03, -1.3801e-03, -9.5609e-04,\n",
      "        -1.1237e-03, -9.2738e-04,  1.4394e-03, -2.7893e-03, -6.3059e-03,\n",
      "        -8.8670e-04, -2.2129e-03, -1.3795e-03, -1.6969e-03, -2.6276e-03,\n",
      "        -8.0724e-05,  7.1520e-05, -6.2530e-03,  1.4927e-03, -2.7080e-03,\n",
      "        -1.6656e-03, -1.8949e-03, -9.7204e-04, -6.0433e-06, -4.0290e-03,\n",
      "        -2.8173e-03, -1.7390e-03, -8.4444e-04, -6.1480e-03,  9.6033e-04,\n",
      "        -3.6468e-03, -1.0600e-03, -2.3079e-04, -2.2570e-03, -6.4991e-04,\n",
      "        -2.9730e-03, -1.3361e-03,  2.1315e-03, -4.7718e-03,  5.6733e-04,\n",
      "         6.0394e-04, -6.6495e-04, -6.0916e-03,  2.3890e-03, -2.1311e-03,\n",
      "        -8.4013e-03, -1.0655e-03, -1.3623e-03, -5.2603e-03, -1.7644e-03,\n",
      "        -3.1050e-04, -5.2856e-04,  7.0440e-04,  4.8335e-04, -2.5614e-03,\n",
      "        -3.7249e-03, -3.3561e-03, -2.4508e-03, -7.6640e-04], device='cuda:0')\n",
      "layer3.0.weight tensor([[[[-2.2623e-02,  4.4575e-03,  3.6200e-02],\n",
      "          [-1.6255e-03,  3.4683e-03,  2.6924e-02],\n",
      "          [ 3.1883e-02,  7.0902e-03,  1.7571e-03]],\n",
      "\n",
      "         [[ 1.5598e-02, -2.6401e-02,  6.6271e-05],\n",
      "          [ 3.5262e-02,  2.1742e-02,  7.7548e-03],\n",
      "          [-1.9838e-02, -2.3912e-02,  2.0495e-02]],\n",
      "\n",
      "         [[-9.8414e-03, -3.3061e-02,  1.4118e-03],\n",
      "          [ 1.2006e-02,  1.7954e-02,  1.4362e-02],\n",
      "          [ 2.6136e-02, -1.4082e-02,  6.5775e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2609e-02,  2.7743e-02, -2.8224e-02],\n",
      "          [ 3.0359e-02,  6.5257e-03, -1.6567e-02],\n",
      "          [-8.1984e-03, -3.4291e-02, -2.2221e-02]],\n",
      "\n",
      "         [[ 6.2941e-03, -2.0666e-02,  5.3862e-03],\n",
      "          [-6.5033e-03,  2.9799e-02,  1.6042e-02],\n",
      "          [-4.1787e-02,  1.5814e-02, -6.4432e-03]],\n",
      "\n",
      "         [[ 3.0867e-02,  2.2849e-02,  8.7605e-03],\n",
      "          [-2.5093e-02, -2.4743e-02,  6.4797e-03],\n",
      "          [-1.9237e-02, -4.6497e-03, -1.2188e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0711e-02,  3.2211e-02, -3.9708e-03],\n",
      "          [ 2.0149e-02, -1.7430e-03,  2.7177e-02],\n",
      "          [ 1.2457e-03, -1.2640e-02, -1.7675e-03]],\n",
      "\n",
      "         [[ 1.3270e-02,  3.3634e-02,  7.9760e-03],\n",
      "          [-1.5298e-02,  1.8542e-02,  3.1375e-02],\n",
      "          [ 3.4416e-02, -1.2189e-02, -3.5778e-02]],\n",
      "\n",
      "         [[-1.0345e-02,  8.0558e-03,  2.2658e-02],\n",
      "          [-2.5956e-02,  2.6538e-02,  2.6056e-03],\n",
      "          [-4.6386e-03,  1.2937e-02,  6.2100e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8404e-02,  3.6967e-02,  6.5915e-03],\n",
      "          [ 6.7288e-03,  3.8025e-02, -3.2774e-02],\n",
      "          [-3.3533e-02,  1.7249e-02, -2.5470e-02]],\n",
      "\n",
      "         [[ 3.0716e-02, -1.6250e-02, -3.5099e-02],\n",
      "          [-3.5824e-02,  3.7937e-02, -3.0099e-02],\n",
      "          [-1.7901e-03,  2.7128e-02, -2.3508e-03]],\n",
      "\n",
      "         [[ 2.2399e-02,  3.3478e-02, -2.6733e-02],\n",
      "          [ 3.2332e-02, -1.9630e-02, -5.2024e-04],\n",
      "          [-2.8094e-02, -3.4373e-02, -1.5879e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.0217e-03, -2.5933e-02,  2.6591e-02],\n",
      "          [ 2.8653e-02, -4.4491e-03, -2.8674e-02],\n",
      "          [-3.8222e-02, -8.5605e-03,  9.2336e-03]],\n",
      "\n",
      "         [[-1.8135e-02,  1.2443e-02, -6.1085e-03],\n",
      "          [-1.9233e-02, -3.0284e-03, -8.1784e-03],\n",
      "          [-2.6548e-02, -1.3548e-02,  1.2669e-02]],\n",
      "\n",
      "         [[-1.4737e-03,  1.1439e-02, -1.5917e-02],\n",
      "          [ 1.5505e-03, -1.9154e-02,  2.8617e-02],\n",
      "          [ 5.5920e-03, -3.4468e-02, -3.3922e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2266e-02,  1.6516e-02, -5.1178e-03],\n",
      "          [ 3.0136e-02, -2.9530e-02,  1.4813e-02],\n",
      "          [ 1.8133e-02, -2.1900e-02,  3.6899e-02]],\n",
      "\n",
      "         [[ 3.1952e-02,  6.5692e-03,  1.3743e-02],\n",
      "          [-3.5392e-02, -1.3036e-03, -5.0212e-03],\n",
      "          [ 3.1874e-02, -1.8959e-02,  6.9712e-03]],\n",
      "\n",
      "         [[ 4.7165e-03, -2.7447e-02,  3.6610e-02],\n",
      "          [-1.7070e-02, -2.0970e-02, -3.0706e-02],\n",
      "          [-2.8431e-02, -9.8063e-03, -1.0097e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1554e-02,  9.9188e-03,  2.4565e-02],\n",
      "          [-2.3270e-02, -3.3081e-02, -1.5919e-02],\n",
      "          [ 2.5309e-02,  4.0552e-03,  2.9103e-02]],\n",
      "\n",
      "         [[ 1.9687e-02,  2.7344e-02, -1.1431e-02],\n",
      "          [ 1.8454e-02, -2.3734e-02,  1.0211e-02],\n",
      "          [-9.9889e-03, -6.4287e-03,  7.7847e-03]],\n",
      "\n",
      "         [[ 3.3724e-02, -2.6913e-02,  1.4467e-02],\n",
      "          [ 1.7632e-02, -3.8450e-03, -1.6326e-02],\n",
      "          [ 3.7589e-03,  3.0409e-02,  3.8713e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5618e-02,  2.6470e-02,  4.3815e-03],\n",
      "          [-2.5812e-02,  3.2235e-02, -2.4333e-02],\n",
      "          [ 4.7371e-03,  2.2759e-02, -3.4009e-02]],\n",
      "\n",
      "         [[ 2.9729e-02, -2.4793e-02,  2.1229e-02],\n",
      "          [-6.6982e-03,  1.6410e-02, -2.5466e-03],\n",
      "          [-3.7217e-02,  5.9466e-03,  1.4162e-02]],\n",
      "\n",
      "         [[ 4.8915e-03,  4.8512e-03,  2.3062e-02],\n",
      "          [ 1.6096e-02, -3.5723e-02,  5.7907e-03],\n",
      "          [-3.6666e-02,  6.8738e-03,  3.1208e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7467e-02,  1.0927e-02,  1.8902e-02],\n",
      "          [ 2.2642e-02,  2.7251e-02, -2.2606e-02],\n",
      "          [-2.6235e-02,  5.6012e-03, -9.9325e-03]],\n",
      "\n",
      "         [[-3.0487e-02,  2.0754e-02,  1.9213e-02],\n",
      "          [ 2.5131e-02, -3.4656e-02, -1.6325e-02],\n",
      "          [-3.3175e-02,  1.7633e-02, -3.0805e-02]],\n",
      "\n",
      "         [[-4.0011e-02,  2.2785e-02,  8.6308e-03],\n",
      "          [-2.7283e-03,  3.2219e-02, -1.5042e-02],\n",
      "          [-1.1610e-02, -1.0621e-02,  3.5454e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.9956e-03,  1.6705e-02, -2.9792e-02],\n",
      "          [-2.9538e-02, -4.0542e-02,  3.3037e-02],\n",
      "          [-5.5057e-03, -1.7943e-03, -3.5317e-02]],\n",
      "\n",
      "         [[-1.8683e-02, -3.1659e-02,  1.7266e-02],\n",
      "          [ 3.2677e-04,  1.1845e-02, -4.2338e-03],\n",
      "          [ 2.5665e-02,  9.2350e-03,  1.7141e-02]],\n",
      "\n",
      "         [[ 1.3564e-02,  9.7430e-03,  3.8948e-02],\n",
      "          [-2.4403e-02, -3.0514e-02,  1.1835e-02],\n",
      "          [ 2.0151e-02, -8.8916e-03, -1.6730e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7044e-04, -3.1443e-02, -3.1652e-02],\n",
      "          [ 2.3739e-02, -3.7058e-02,  3.2641e-02],\n",
      "          [ 3.5142e-02,  9.7294e-03, -1.0496e-02]],\n",
      "\n",
      "         [[ 2.4822e-02, -2.0496e-02,  1.9984e-02],\n",
      "          [ 1.9650e-03, -1.4900e-02,  3.1083e-02],\n",
      "          [-5.4632e-03, -1.2097e-02,  3.6013e-02]],\n",
      "\n",
      "         [[ 1.2383e-03,  2.0948e-02,  6.2972e-03],\n",
      "          [ 5.2488e-03,  2.0834e-02,  4.9272e-03],\n",
      "          [ 3.0914e-02, -3.9971e-03, -1.0476e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4626e-03, -1.7901e-02, -1.9376e-02],\n",
      "          [ 1.5116e-02,  7.4225e-03, -3.7519e-03],\n",
      "          [-1.9551e-03, -5.7949e-03,  2.1635e-02]],\n",
      "\n",
      "         [[ 3.6136e-02,  1.4468e-02,  1.7632e-02],\n",
      "          [ 3.5777e-02, -3.5381e-02,  3.6075e-02],\n",
      "          [ 1.7983e-02,  4.8076e-03, -2.5816e-02]],\n",
      "\n",
      "         [[ 3.6056e-02,  1.2488e-02,  2.6708e-02],\n",
      "          [ 3.5680e-02,  1.5954e-02, -2.0707e-02],\n",
      "          [ 3.3605e-02, -2.7237e-02, -2.3761e-02]]]], device='cuda:0')\n",
      "layer3.0.bias tensor([-2.8109e-03,  2.0929e-02, -2.9223e-02,  1.0861e-02,  2.7917e-02,\n",
      "         8.0054e-03,  3.5390e-02, -2.6859e-03,  1.4489e-02, -2.8586e-02,\n",
      "         3.7131e-02,  1.2811e-02,  2.4726e-02, -2.6132e-03, -2.8376e-02,\n",
      "         3.5022e-02, -9.5058e-03,  3.2290e-02, -3.6460e-02,  1.0620e-02,\n",
      "        -2.1017e-02, -1.5023e-02,  3.4347e-02, -1.2383e-05,  1.0328e-02,\n",
      "         3.6225e-02,  1.5327e-02, -2.2754e-02, -3.4279e-02, -8.8819e-03,\n",
      "        -9.8926e-03,  2.4020e-02, -1.8801e-02, -6.2960e-03,  4.1134e-03,\n",
      "        -2.4976e-02,  2.3433e-02, -2.0521e-02,  3.0213e-02, -2.0703e-02,\n",
      "         3.2841e-02, -2.7723e-02,  2.4848e-02,  3.9024e-03,  3.6719e-02,\n",
      "         2.8453e-02,  3.2471e-02, -1.1255e-02, -3.1099e-02, -3.6729e-02,\n",
      "        -3.1842e-02, -1.2415e-02,  5.3421e-03,  1.5716e-02,  1.5299e-02,\n",
      "         1.8411e-02,  1.2686e-02,  2.0527e-02,  3.3720e-02,  1.6828e-02,\n",
      "         3.1093e-02, -9.2034e-03, -3.0768e-02,  2.5873e-03, -8.2188e-03,\n",
      "        -1.6583e-02, -2.0659e-02, -3.5260e-02, -4.0360e-03, -1.4935e-02,\n",
      "         6.1668e-03,  2.8165e-02,  5.3948e-03,  2.0558e-02,  1.7076e-02,\n",
      "        -2.5971e-02, -2.0005e-02,  1.8881e-02, -3.5455e-02, -2.1547e-02,\n",
      "         8.2954e-04, -3.1921e-02,  1.2734e-02, -1.3516e-02,  4.4189e-04,\n",
      "         3.6171e-02,  2.6725e-02,  7.9242e-03, -3.6464e-02, -1.5225e-02,\n",
      "         1.0664e-02,  9.7225e-04,  2.9481e-02, -1.0468e-02, -1.2993e-02,\n",
      "         1.9049e-02,  3.1752e-02,  3.2140e-02,  1.1522e-02,  3.2349e-02,\n",
      "         3.1428e-02,  3.1204e-02,  1.9181e-02, -3.4107e-03, -3.5657e-02,\n",
      "         1.8675e-02,  1.6073e-02,  8.5510e-03,  2.0710e-02, -1.9959e-02,\n",
      "        -9.6909e-03, -3.3094e-02,  2.0374e-02,  1.8441e-02,  1.0649e-02,\n",
      "         1.2421e-02,  3.7208e-02,  2.0696e-02,  2.4638e-02,  3.4707e-02,\n",
      "         1.3518e-03, -1.1223e-02, -7.6096e-03,  3.1525e-03,  1.1008e-03,\n",
      "         2.2229e-02,  2.4237e-02,  2.6562e-02], device='cuda:0')\n",
      "layer3.1.weight tensor([0.9046, 0.9056, 0.9063, 0.9051, 0.9043, 0.9050, 0.9084, 0.9046, 0.9058,\n",
      "        0.9098, 0.9029, 0.9048, 0.9064, 0.9049, 0.9049, 0.9034, 0.9078, 0.9079,\n",
      "        0.9039, 0.9046, 0.9068, 0.9032, 0.9039, 0.9064, 0.9039, 0.9057, 0.9033,\n",
      "        0.9100, 0.9066, 0.9052, 0.9054, 0.9050, 0.9073, 0.9039, 0.9093, 0.9031,\n",
      "        0.9048, 0.9039, 0.9042, 0.9051, 0.9122, 0.9023, 0.9024, 0.9037, 0.9036,\n",
      "        0.9065, 0.9030, 0.9035, 0.9060, 0.9046, 0.9051, 0.9046, 0.9039, 0.9045,\n",
      "        0.9024, 0.9042, 0.9052, 0.9076, 0.9073, 0.9050, 0.9023, 0.9055, 0.9070,\n",
      "        0.9041, 0.9062, 0.9044, 0.9079, 0.9049, 0.9045, 0.9034, 0.9040, 0.9045,\n",
      "        0.9057, 0.9037, 0.9042, 0.9033, 0.9026, 0.9038, 0.9067, 0.9034, 0.9072,\n",
      "        0.9055, 0.9080, 0.9062, 0.9041, 0.9060, 0.9070, 0.9043, 0.9040, 0.9053,\n",
      "        0.9037, 0.9046, 0.9050, 0.9048, 0.9028, 0.9042, 0.9065, 0.9051, 0.9037,\n",
      "        0.9026, 0.9074, 0.9016, 0.9049, 0.9051, 0.9046, 0.9049, 0.9056, 0.9068,\n",
      "        0.9087, 0.9033, 0.9078, 0.9071, 0.9040, 0.9047, 0.9037, 0.9039, 0.9098,\n",
      "        0.9045, 0.9016, 0.9091, 0.9072, 0.9040, 0.9069, 0.9088, 0.9049, 0.9062,\n",
      "        0.9047, 0.9054], device='cuda:0')\n",
      "layer3.1.bias tensor([-2.8777e-03, -1.6816e-03, -1.4414e-03,  1.4060e-04, -8.9120e-04,\n",
      "         1.8747e-04, -3.6843e-03, -3.7423e-03, -2.6213e-03,  3.2538e-03,\n",
      "        -3.7568e-03,  7.8195e-05, -1.6729e-03,  5.3069e-05,  2.7305e-04,\n",
      "        -2.0753e-03,  4.5994e-04, -2.7325e-03, -2.1992e-03,  7.1105e-05,\n",
      "        -6.0410e-04, -2.7128e-03, -2.0328e-03,  1.3780e-03, -1.2253e-03,\n",
      "        -1.3887e-03, -1.7735e-03, -2.3256e-04,  7.0609e-04, -2.6015e-03,\n",
      "        -7.5472e-04, -3.6028e-03,  9.2925e-05, -4.3352e-04, -3.9246e-03,\n",
      "        -1.9000e-03, -1.5232e-03, -2.7216e-03, -1.5890e-03, -3.4185e-03,\n",
      "        -4.8749e-03, -1.5455e-03, -2.6099e-03, -2.0704e-03, -1.5769e-03,\n",
      "        -4.2668e-03, -2.2127e-03, -7.4053e-04, -2.9108e-03, -1.3582e-03,\n",
      "        -2.5091e-03, -8.8048e-04, -7.1323e-04, -3.7912e-04, -2.0004e-03,\n",
      "        -1.6622e-03, -1.3192e-03,  1.5418e-04, -2.1189e-03, -8.9844e-04,\n",
      "        -1.7930e-03, -3.1109e-03, -1.5084e-03, -1.4768e-03, -2.0009e-03,\n",
      "        -9.5539e-04, -5.2692e-03, -7.0722e-04, -8.5554e-04, -3.7361e-03,\n",
      "        -2.6188e-03, -6.4110e-04, -6.1459e-04, -2.3979e-03, -3.6697e-03,\n",
      "        -3.3427e-03, -1.1035e-03, -1.6319e-03, -2.0489e-03, -1.7015e-03,\n",
      "         4.9763e-04, -2.3864e-03, -2.2319e-04, -3.2509e-03,  1.8562e-04,\n",
      "         1.8607e-03,  9.7111e-04, -7.7110e-04, -1.8427e-03, -3.6591e-03,\n",
      "        -1.5742e-03, -5.1248e-04, -1.8200e-04, -6.6699e-04, -3.8123e-03,\n",
      "        -4.9929e-04, -9.3562e-04, -2.1115e-03, -2.4185e-03, -1.4189e-03,\n",
      "        -5.2794e-03, -1.8996e-03, -6.7822e-04, -1.8741e-03, -6.7050e-04,\n",
      "         8.0612e-05, -2.0823e-03, -2.0398e-03, -2.4854e-03, -3.2682e-03,\n",
      "        -1.7918e-03, -2.3931e-03, -2.7517e-03, -8.7124e-04, -1.8932e-03,\n",
      "        -1.8163e-03, -4.0782e-03, -4.3565e-04, -1.8855e-03, -6.8168e-05,\n",
      "        -2.7398e-03, -2.9931e-03,  1.0768e-03, -1.6772e-03,  4.0555e-04,\n",
      "        -1.0234e-03, -5.2203e-04, -1.0888e-03], device='cuda:0')\n",
      "layer4.0.weight tensor([[[[-0.0134,  0.0062,  0.0039],\n",
      "          [ 0.0102, -0.0156,  0.0216],\n",
      "          [-0.0083,  0.0168, -0.0082]],\n",
      "\n",
      "         [[-0.0099, -0.0106, -0.0215],\n",
      "          [ 0.0108,  0.0103, -0.0196],\n",
      "          [ 0.0212, -0.0263, -0.0081]],\n",
      "\n",
      "         [[-0.0073, -0.0082,  0.0244],\n",
      "          [-0.0259, -0.0234, -0.0197],\n",
      "          [-0.0156,  0.0169,  0.0143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0253,  0.0050,  0.0126],\n",
      "          [-0.0052, -0.0125,  0.0146],\n",
      "          [-0.0033,  0.0151,  0.0105]],\n",
      "\n",
      "         [[-0.0250,  0.0194,  0.0174],\n",
      "          [-0.0189,  0.0267, -0.0121],\n",
      "          [ 0.0056,  0.0058, -0.0071]],\n",
      "\n",
      "         [[-0.0057,  0.0165, -0.0184],\n",
      "          [-0.0142, -0.0245, -0.0202],\n",
      "          [-0.0030, -0.0242,  0.0161]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0143,  0.0151,  0.0001],\n",
      "          [-0.0092,  0.0064,  0.0075],\n",
      "          [-0.0187,  0.0004,  0.0079]],\n",
      "\n",
      "         [[ 0.0075, -0.0015,  0.0101],\n",
      "          [ 0.0083,  0.0127,  0.0203],\n",
      "          [ 0.0148, -0.0090, -0.0059]],\n",
      "\n",
      "         [[ 0.0150, -0.0212,  0.0172],\n",
      "          [ 0.0189,  0.0224, -0.0140],\n",
      "          [ 0.0002,  0.0229,  0.0079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0176,  0.0013, -0.0177],\n",
      "          [ 0.0103, -0.0224,  0.0009],\n",
      "          [ 0.0053, -0.0075, -0.0075]],\n",
      "\n",
      "         [[ 0.0088, -0.0002, -0.0232],\n",
      "          [ 0.0087,  0.0260,  0.0076],\n",
      "          [-0.0226, -0.0133, -0.0141]],\n",
      "\n",
      "         [[-0.0014, -0.0135, -0.0096],\n",
      "          [-0.0255,  0.0146, -0.0224],\n",
      "          [ 0.0229, -0.0020, -0.0176]]],\n",
      "\n",
      "\n",
      "        [[[-0.0107,  0.0244,  0.0255],\n",
      "          [ 0.0095, -0.0233, -0.0158],\n",
      "          [ 0.0014,  0.0015, -0.0074]],\n",
      "\n",
      "         [[ 0.0064, -0.0092, -0.0165],\n",
      "          [-0.0260,  0.0222,  0.0066],\n",
      "          [ 0.0244, -0.0077, -0.0025]],\n",
      "\n",
      "         [[-0.0264,  0.0154,  0.0218],\n",
      "          [ 0.0085,  0.0063, -0.0065],\n",
      "          [-0.0091,  0.0176, -0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0170, -0.0235, -0.0120],\n",
      "          [ 0.0159, -0.0181,  0.0126],\n",
      "          [ 0.0026,  0.0099,  0.0078]],\n",
      "\n",
      "         [[ 0.0109, -0.0049,  0.0097],\n",
      "          [-0.0141,  0.0108,  0.0079],\n",
      "          [ 0.0136,  0.0113, -0.0141]],\n",
      "\n",
      "         [[-0.0018,  0.0101, -0.0143],\n",
      "          [ 0.0076, -0.0130,  0.0256],\n",
      "          [ 0.0030,  0.0121, -0.0182]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0256, -0.0033, -0.0153],\n",
      "          [-0.0167,  0.0091,  0.0051],\n",
      "          [-0.0062, -0.0241, -0.0199]],\n",
      "\n",
      "         [[ 0.0111, -0.0159,  0.0157],\n",
      "          [-0.0055, -0.0005, -0.0135],\n",
      "          [-0.0058,  0.0177, -0.0269]],\n",
      "\n",
      "         [[ 0.0064,  0.0065, -0.0150],\n",
      "          [-0.0107,  0.0125, -0.0080],\n",
      "          [ 0.0004, -0.0143, -0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0234,  0.0053, -0.0140],\n",
      "          [ 0.0202,  0.0085, -0.0113],\n",
      "          [-0.0119,  0.0136, -0.0131]],\n",
      "\n",
      "         [[ 0.0101, -0.0244, -0.0229],\n",
      "          [-0.0232,  0.0183,  0.0181],\n",
      "          [-0.0077, -0.0133,  0.0155]],\n",
      "\n",
      "         [[-0.0069,  0.0159,  0.0208],\n",
      "          [-0.0222,  0.0047, -0.0135],\n",
      "          [ 0.0068, -0.0212, -0.0160]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0148,  0.0090,  0.0208],\n",
      "          [ 0.0118,  0.0085, -0.0137],\n",
      "          [ 0.0226, -0.0162, -0.0264]],\n",
      "\n",
      "         [[ 0.0018, -0.0021, -0.0157],\n",
      "          [-0.0056,  0.0148, -0.0060],\n",
      "          [ 0.0043, -0.0034, -0.0202]],\n",
      "\n",
      "         [[-0.0193, -0.0181, -0.0136],\n",
      "          [ 0.0216,  0.0155,  0.0037],\n",
      "          [ 0.0068,  0.0214,  0.0215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0262, -0.0185, -0.0184],\n",
      "          [-0.0243,  0.0127, -0.0159],\n",
      "          [ 0.0196, -0.0123, -0.0039]],\n",
      "\n",
      "         [[ 0.0024, -0.0190, -0.0193],\n",
      "          [-0.0229, -0.0155,  0.0120],\n",
      "          [ 0.0228, -0.0030, -0.0201]],\n",
      "\n",
      "         [[-0.0094,  0.0046, -0.0117],\n",
      "          [-0.0054, -0.0121,  0.0072],\n",
      "          [ 0.0184, -0.0188, -0.0155]]],\n",
      "\n",
      "\n",
      "        [[[-0.0165,  0.0111, -0.0132],\n",
      "          [-0.0031,  0.0275,  0.0272],\n",
      "          [ 0.0117, -0.0002, -0.0200]],\n",
      "\n",
      "         [[-0.0126,  0.0267,  0.0287],\n",
      "          [ 0.0015, -0.0264,  0.0255],\n",
      "          [-0.0036, -0.0322, -0.0161]],\n",
      "\n",
      "         [[-0.0294,  0.0073, -0.0187],\n",
      "          [-0.0099,  0.0065,  0.0169],\n",
      "          [ 0.0092,  0.0251, -0.0120]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0093, -0.0067,  0.0129],\n",
      "          [-0.0015,  0.0050, -0.0154],\n",
      "          [-0.0149, -0.0281, -0.0043]],\n",
      "\n",
      "         [[-0.0165, -0.0247, -0.0229],\n",
      "          [-0.0211, -0.0020, -0.0142],\n",
      "          [ 0.0174, -0.0112, -0.0186]],\n",
      "\n",
      "         [[ 0.0053,  0.0126,  0.0150],\n",
      "          [ 0.0094, -0.0072,  0.0094],\n",
      "          [-0.0255, -0.0119, -0.0139]]]], device='cuda:0')\n",
      "layer4.0.bias tensor([ 0.0259, -0.0186,  0.0105,  0.0157,  0.0030, -0.0246,  0.0061,  0.0016,\n",
      "         0.0005,  0.0168, -0.0210,  0.0022, -0.0061,  0.0130, -0.0108, -0.0067,\n",
      "         0.0178,  0.0016, -0.0048,  0.0047, -0.0082, -0.0170, -0.0058, -0.0206,\n",
      "         0.0055, -0.0090,  0.0124, -0.0225,  0.0120, -0.0206,  0.0177, -0.0213,\n",
      "         0.0033,  0.0236, -0.0243,  0.0191, -0.0134,  0.0152, -0.0101, -0.0010,\n",
      "        -0.0160, -0.0059, -0.0017, -0.0198,  0.0254,  0.0147, -0.0249, -0.0161,\n",
      "         0.0163,  0.0136, -0.0050, -0.0199, -0.0010,  0.0242,  0.0246,  0.0153,\n",
      "        -0.0009, -0.0218, -0.0062,  0.0233, -0.0121,  0.0026, -0.0203,  0.0071,\n",
      "        -0.0150,  0.0232,  0.0214, -0.0205, -0.0049, -0.0053, -0.0113,  0.0209,\n",
      "        -0.0103,  0.0074, -0.0114, -0.0122, -0.0119, -0.0114, -0.0095, -0.0162,\n",
      "        -0.0206,  0.0116,  0.0189,  0.0127, -0.0137, -0.0184, -0.0191, -0.0183,\n",
      "        -0.0119, -0.0022,  0.0022,  0.0256, -0.0066,  0.0041,  0.0102,  0.0213,\n",
      "         0.0204,  0.0253,  0.0135, -0.0126,  0.0247, -0.0116, -0.0154,  0.0089,\n",
      "         0.0033,  0.0005,  0.0162,  0.0225,  0.0231,  0.0260,  0.0002,  0.0081,\n",
      "        -0.0171, -0.0211,  0.0203,  0.0246, -0.0078, -0.0241, -0.0028, -0.0170,\n",
      "        -0.0004,  0.0012,  0.0138, -0.0065,  0.0069,  0.0180, -0.0023, -0.0127],\n",
      "       device='cuda:0')\n",
      "layer4.1.weight tensor([0.8960, 0.8982, 0.9006, 0.8970, 0.8961, 0.8982, 0.8987, 0.8979, 0.8990,\n",
      "        0.9007, 0.8997, 0.8959, 0.9009, 0.8987, 0.8992, 0.8979, 0.8975, 0.8967,\n",
      "        0.8983, 0.8967, 0.8999, 0.9004, 0.8966, 0.9011, 0.8981, 0.8987, 0.9016,\n",
      "        0.8965, 0.8996, 0.8994, 0.8995, 0.8966, 0.9006, 0.8988, 0.8998, 0.8967,\n",
      "        0.8990, 0.8983, 0.8953, 0.8930, 0.9089, 0.8979, 0.9012, 0.8957, 0.8997,\n",
      "        0.8967, 0.9069, 0.8963, 0.9000, 0.8999, 0.9003, 0.8989, 0.8996, 0.9006,\n",
      "        0.8987, 0.8999, 0.8991, 0.9004, 0.8988, 0.8969, 0.8967, 0.8990, 0.8998,\n",
      "        0.9011, 0.9003, 0.8849, 0.8979, 0.8996, 0.8958, 0.9088, 0.9000, 0.9004,\n",
      "        0.8990, 0.9000, 0.8985, 0.8945, 0.8988, 0.9053, 0.8990, 0.8976, 0.9016,\n",
      "        0.8953, 0.8968, 0.8983, 0.9001, 0.8986, 0.8997, 0.8983, 0.8996, 0.8984,\n",
      "        0.8994, 0.8998, 0.8963, 0.9002, 0.8990, 0.8969, 0.8977, 0.8979, 0.9000,\n",
      "        0.8995, 0.8978, 0.8992, 0.9014, 0.8980, 0.8963, 0.9029, 0.9000, 0.9004,\n",
      "        0.8878, 0.8995, 0.8950, 0.8979, 0.8999, 0.8990, 0.9008, 0.8970, 0.8986,\n",
      "        0.8996, 0.9112, 0.9007, 0.8971, 0.9010, 0.8917, 0.9008, 0.8986, 0.8993,\n",
      "        0.9001, 0.9167], device='cuda:0')\n",
      "layer4.1.bias tensor([-0.0184, -0.0156, -0.0140, -0.0180, -0.0167, -0.0104, -0.0151, -0.0172,\n",
      "        -0.0135, -0.0139, -0.0153, -0.0181, -0.0146, -0.0182, -0.0161, -0.0163,\n",
      "        -0.0147, -0.0181, -0.0154, -0.0178, -0.0150, -0.0124, -0.0136, -0.0145,\n",
      "        -0.0136, -0.0153, -0.0166, -0.0191, -0.0152, -0.0159, -0.0158, -0.0176,\n",
      "        -0.0132, -0.0149, -0.0134, -0.0184, -0.0162, -0.0164, -0.0147, -0.0114,\n",
      "        -0.0120, -0.0165, -0.0139, -0.0170, -0.0165, -0.0174, -0.0131, -0.0198,\n",
      "        -0.0160, -0.0153, -0.0137, -0.0148, -0.0153, -0.0130, -0.0146, -0.0142,\n",
      "        -0.0150, -0.0114, -0.0165, -0.0168, -0.0166, -0.0162, -0.0161, -0.0130,\n",
      "        -0.0145, -0.0124, -0.0172, -0.0167, -0.0182, -0.0126, -0.0148, -0.0128,\n",
      "        -0.0147, -0.0151, -0.0149, -0.0130, -0.0176, -0.0053, -0.0133, -0.0128,\n",
      "        -0.0165, -0.0202, -0.0184, -0.0174, -0.0145, -0.0164, -0.0157, -0.0154,\n",
      "        -0.0145, -0.0151, -0.0146, -0.0178, -0.0140, -0.0152, -0.0154, -0.0188,\n",
      "        -0.0156, -0.0168, -0.0153, -0.0152, -0.0175, -0.0159, -0.0130, -0.0170,\n",
      "        -0.0185, -0.0153, -0.0148, -0.0137, -0.0149, -0.0162, -0.0164, -0.0171,\n",
      "        -0.0147, -0.0164, -0.0149, -0.0163, -0.0155, -0.0161, -0.0076, -0.0141,\n",
      "        -0.0172, -0.0103, -0.0149, -0.0149, -0.0170, -0.0152, -0.0140, -0.0134],\n",
      "       device='cuda:0')\n",
      "fc0.1.weight tensor([[ 5.0244e-04,  1.5174e-03, -4.7885e-05,  ...,  1.4460e-03,\n",
      "         -4.2077e-04,  1.1027e-03],\n",
      "        [-1.6893e-03,  1.4771e-03,  2.1262e-03,  ..., -1.7880e-03,\n",
      "          1.1649e-03,  2.7508e-04],\n",
      "        [ 9.7023e-04, -2.1891e-03,  7.9431e-04,  ...,  7.4342e-04,\n",
      "          8.3368e-04, -1.0410e-04],\n",
      "        ...,\n",
      "        [-2.3576e-03, -1.6525e-03,  1.2762e-03,  ..., -1.8185e-03,\n",
      "          6.2347e-04,  6.0735e-06],\n",
      "        [-1.5876e-05,  5.8758e-04, -2.3346e-03,  ...,  2.3082e-03,\n",
      "          1.5943e-03, -5.3781e-04],\n",
      "        [ 1.5517e-03,  2.0868e-03,  8.0552e-04,  ..., -1.3412e-03,\n",
      "          1.1873e-03, -2.5474e-03]], device='cuda:0')\n",
      "fc0.1.bias tensor([ 0.0015,  0.0011, -0.0012,  ..., -0.0009,  0.0003,  0.0002],\n",
      "       device='cuda:0')\n",
      "fc1.1.weight tensor([[-0.0038,  0.0138,  0.0054,  ..., -0.0027, -0.0006, -0.0129],\n",
      "        [-0.0099, -0.0016,  0.0133,  ..., -0.0067, -0.0078,  0.0111],\n",
      "        [ 0.0125, -0.0096, -0.0060,  ..., -0.0067, -0.0085, -0.0107],\n",
      "        ...,\n",
      "        [-0.0024,  0.0135,  0.0065,  ...,  0.0106, -0.0133, -0.0055],\n",
      "        [-0.0123, -0.0129, -0.0087,  ...,  0.0075,  0.0102,  0.0010],\n",
      "        [ 0.0094, -0.0131,  0.0044,  ...,  0.0034,  0.0115,  0.0118]],\n",
      "       device='cuda:0')\n",
      "fc1.1.bias tensor([ 0.0039, -0.0018, -0.0140,  ...,  0.0105, -0.0113, -0.0061],\n",
      "       device='cuda:0')\n",
      "fc2.0.weight tensor([[-0.0039,  0.0018, -0.0045,  ..., -0.0053, -0.0097, -0.0088],\n",
      "        [-0.0123,  0.0136,  0.0033,  ..., -0.0023,  0.0043, -0.0114]],\n",
      "       device='cuda:0')\n",
      "fc2.0.bias tensor([-0.0195,  0.0164], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(FULL_REPO_MODEL_PATH, \"metric_model.pth\")))\n",
    "model.to(DEVICE) # Place model on GPU\n",
    "model.eval()\n",
    "\n",
    "## PRINT MODEL\n",
    "print(f'====================================================')\n",
    "print(model)\n",
    "\n",
    "### PRINT model.named_parameters\n",
    "print(f'====================================================')\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd7628",
   "metadata": {},
   "source": [
    "## 11. Evaluate the model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3791b35a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:56.922031Z",
     "start_time": "2022-08-31T12:16:55.416640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      " Dataset details \n",
      " class_distribution(val_dataset): {'BKGR': 5, '4CV': 5}\n",
      " len(val_dataloader): 1\n",
      " BATCH_SIZE_OF_CLIPS: 10\n",
      "==================================================\n",
      " BATCH_OF_CLIPS_INDEX: 0 \n",
      "   X_train_batch.size(): torch.Size([10, 1, 5, 128, 128])\n",
      "   y_train_batch.size(): torch.Size([10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mx19/anaconda3/envs/rt-ai-echo-VE/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-pma2oi4d/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_test_pred.size(): torch.Size([10, 2])\n",
      "==================================================\n",
      "==================================================\n",
      "{'BKGR': 5, '4CV': 5}\n",
      "y_true_list[0, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n",
      "y_pred_list[0, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "print(f'==================================================')\n",
    "print(f' Dataset details ')\n",
    "print(f' class_distribution(val_dataset): {val_set_class_dict}' )\n",
    "print(f' len(val_dataloader): {len(val_dataloader)}')\n",
    "print(f' BATCH_SIZE_OF_CLIPS: {BATCH_SIZE_OF_CLIPS}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for clip_batch_idx, sample_batched in enumerate(val_dataloader):\n",
    "        X_train_batch, y_train_batch = sample_batched[0].to(DEVICE), sample_batched[1].to(DEVICE)\n",
    "        print(f'==================================================')\n",
    "        print(f' BATCH_OF_CLIPS_INDEX: {clip_batch_idx} ')\n",
    "        print(f'   X_train_batch.size(): {X_train_batch.size()}') \n",
    "                                            # torch.Size([10, 1, 5, 128, 128]) \n",
    "                                            #       BATCH_SIZE_OF_CLIPS, channels, frames, [width, height]\n",
    "        print(f'   y_train_batch.size(): {y_train_batch.size()}') \n",
    "                                            # torch.Size([10])\n",
    "                                            #          BATCH_CLIP_LABELs\n",
    "        y_test_pred = model(X_train_batch)\n",
    "        print(f'   y_test_pred.size(): {y_test_pred.size()}') \n",
    "                                            # y_test_pred.size(): torch.Size([BATCH_SIZE_OF_CLIPS, num_classes])\n",
    "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
    "        #print(torch.max(y_test_pred, dim = 1))\n",
    "        #torch.return_types.max(\n",
    "        #values=tensor([0.5229, 0.3555, 0.5858, 0.6710, 0.5659, 0.3931, 0.6405, 0.5488, 0.6074,\n",
    "        #      0.5610]),\n",
    "        #indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
    "                \n",
    "        for i in range(len(y_test_pred)):\n",
    "            y_true_list.append(y_train_batch[i].cpu().item())\n",
    "            y_pred_list.append(y_pred_tag[i].cpu().item())\n",
    "            \n",
    "\n",
    "        \n",
    "print(f'==================================================')        \n",
    "print(f'==================================================')        \n",
    "print(get_class_distribution(val_dataset, label_id))\n",
    "print(f'y_true_list{y_true_list}')\n",
    "print(f'y_pred_list{y_pred_list}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781a2101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:16:57.011967Z",
     "start_time": "2022-08-31T12:16:56.923312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n",
      "                    Precision  Recall  F1-score  Support\n",
      "0                    1.000000     0.8  0.888889      5.0\n",
      "1                    0.833333     1.0  0.909091      5.0\n",
      "weighted avg/Total   0.916667     0.9  0.898990      NaN\n",
      "Avg/Total                 NaN     NaN       NaN     10.0\n",
      "[[4 1]\n",
      " [0 5]]\n",
      "Elapsed time for the notebook loop: 50.98022818565369 (s)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = classification_report(y_true_list, y_pred_list)\n",
    "print(report)\n",
    "# report_support = precision_recall_fscore_support(y_true_list, y_pred_list)\n",
    "# print(report_support)\n",
    "\n",
    "def metrics_report_to_df(ytrue, ypred):\n",
    "    classification_report_df = pd.DataFrame(data=list(precision_recall_fscore_support(y_true_list, y_pred_list)), \\\n",
    "                                         index=['Precision', 'Recall', 'F1-score', 'Support']).T    \n",
    "    classification_report_df.loc['weighted avg/Total', :] = precision_recall_fscore_support(ytrue, ypred, average='weighted')\n",
    "    classification_report_df.loc['Avg/Total', 'Support'] = classification_report_df['Support'].sum()\n",
    "    return(classification_report_df)\n",
    "\n",
    "classification_report_df = metrics_report_to_df(y_true_list, y_pred_list)\n",
    "print(classification_report_df)\n",
    "\n",
    "#################################\n",
    "### PLOTTING CONFUSION MATRIX\n",
    "cm=confusion_matrix(y_true_list, y_pred_list)\n",
    "print(cm)\n",
    "#cm=confusion_matrix(y_true_list, y_pred_list, normalize='all')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['BGR','4CV'])\n",
    "cmd.plot()\n",
    "cmd.ax_.set(xlabel='Predicted', ylabel='True')\n",
    "\n",
    "\n",
    "END_TIME_OF_THE_NOTEBOOK = time.time()\n",
    "NOTEBOOK_ELAPSE_TIME = END_TIME_OF_THE_NOTEBOOK - START_TIME_OF_THE_NOTEBOOK\n",
    "print(f'Elapsed time for the notebook loop: {NOTEBOOK_ELAPSE_TIME} (s)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607176b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T16:44:50.478014Z",
     "start_time": "2022-03-28T16:44:50.470241Z"
    }
   },
   "source": [
    "\n",
    "## File size of models: \n",
    "```\n",
    "cd $HOME/repositories/echocardiography/data/models\n",
    "tree -s\n",
    "\n",
    "tree -s\n",
    ".\n",
    "├── [ 2215719935]  metric_model.pth\n",
    "└── [         80]  README.md\n",
    "\n",
    "0 directories, 2 files\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9403d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72faf859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
